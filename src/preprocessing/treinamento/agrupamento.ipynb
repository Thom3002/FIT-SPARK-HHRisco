{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "from resolve_path import ajuste_path, read_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathUtil = ajuste_path('data/util/')\n",
    "df = pd.read_csv(pathUtil + 'dataset_associado.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passar a data para datetime\n",
    "df['data_inicio'] = pd.to_datetime(df['data_inicio'])\n",
    "df['data_fim'] = pd.to_datetime(df['data_fim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criação da coluna de trabalho por mes\n",
    "df[\"meses\"] = (\n",
    "    (df[\"data_fim\"].dt.year - df[\"data_inicio\"].dt.year) * 12\n",
    "    + (df[\"data_fim\"].dt.month - df[\"data_inicio\"].dt.month)\n",
    ") + 1\n",
    "df[\"hh_por_mes\"] = df[\"hh\"] / df[\"meses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPANSÃO DE OS POR MES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expande_df(df):\n",
    "    # Gerar o espaço de tempo\n",
    "    espaco_de_tempo = pd.date_range(\n",
    "        start='2020-01-01', end=pd.Timestamp.now(), freq=\"MS\")\n",
    "    espaco_de_tempo = pd.DataFrame(\n",
    "        {'merge': [1]*len(espaco_de_tempo), 'ano_mes': espaco_de_tempo})\n",
    "    # Marcar operações que duram mais de um mês\n",
    "    df.loc[df['meses'] > 1, 'dura_mais_de_mes'] = 1\n",
    "\n",
    "    # Dropando colunas desnecessárias\n",
    "    colunas_a_dropar = [\"hh\"]\n",
    "    df = df.drop(columns=colunas_a_dropar)\n",
    "\n",
    "    # Expansão das operações que duram mais de um mês\n",
    "    df_expandido = pd.merge(df, espaco_de_tempo, left_on='dura_mais_de_mes',\n",
    "                            right_on='merge', how='left').drop(columns=['merge'])\n",
    "    return df_expandido\n",
    "\n",
    "\n",
    "df_expandido = expande_df(df)\n",
    "\n",
    "colunas_tipo_atividade = [\"txt.breve_operacao\", \"denominacao_tam\"]\n",
    "# Tratamento das colunas de data para garantir o correto agrupamento\n",
    "df_expandido['dura_mais_de_mes'] = df_expandido['dura_mais_de_mes'].fillna(0)\n",
    "df_expandido.loc[df_expandido['dura_mais_de_mes']\n",
    "                 == 0, 'ano_mes'] = df_expandido['data_fim']\n",
    "df_expandido['ano_mes'] = df_expandido['ano_mes'].dt.to_period('M')\n",
    "df_expandido['data_inicio'] = df_expandido['data_inicio'].dt.to_period('M')\n",
    "df_expandido['data_fim'] = df_expandido['data_fim'].dt.to_period('M')\n",
    "\n",
    "df_expandido['data_acidente'] = pd.to_datetime(df_expandido['data_acidente'])\n",
    "df_expandido['data_acidente'] = df_expandido['data_acidente'].dt.to_period('M')\n",
    "\n",
    "\n",
    "# Eliminar linhas onde a operação não estava ativa\n",
    "df_expandido = df_expandido[(df_expandido['ano_mes'] >= df_expandido['data_inicio']) &\n",
    "                            (df_expandido['ano_mes'] <= df_expandido['data_fim'])]\n",
    "\n",
    "\n",
    "# separar colunas de acidente apenas\n",
    "lista_colunas_acidentes = df_expandido.columns[df_expandido.columns.str.contains(\n",
    "    'acidente')].tolist()\n",
    "\n",
    "# Colocar NAN nas colunas da acidente para as linhas em a data de acidente nao bate com a data da operação\n",
    "df_expandido.loc[(df_expandido['data_acidente'] != pd.NA) & (\n",
    "    df_expandido['ano_mes'] != df_expandido['data_acidente']), lista_colunas_acidentes] = pd.NA\n",
    "\n",
    "\n",
    "# Para cada categoria de atividade, criar uma nova coluna para armazenar o HH dessa categoria\n",
    "for coluna_tipo_atividade in colunas_tipo_atividade:\n",
    "    for atividade in df_expandido[coluna_tipo_atividade].unique():\n",
    "        if \"hh_de_\" + atividade in df_expandido.columns:\n",
    "            df_expandido.loc[df_expandido[coluna_tipo_atividade] == atividade,\n",
    "                             \"hh_de_\" + atividade + \"_de_\" + coluna_tipo_atividade] = df_expandido[\"hh_por_mes\"]\n",
    "        else:\n",
    "            df_expandido.loc[df_expandido[coluna_tipo_atividade] == atividade,\n",
    "                             \"hh_de_\" + atividade] = df_expandido[\"hh_por_mes\"]\n",
    "\n",
    "df_expandido.drop(columns=['txt.breve_operacao',\n",
    "                  'tam', 'denominacao_tam'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CRIAÇÃO DE DICIONÁRIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dicionario, indicando qual operação será efetuada sobre quais colunas durante o agrupamento\n",
    "\n",
    "# Retirando as colunas que são as variáveis do groupby da lista do dicionário\n",
    "colunas = list(df_expandido.columns)\n",
    "colunas.remove(\"no_pessoal\")\n",
    "colunas.remove(\"local_de_instalacao\")\n",
    "colunas.remove(\"ano_mes\")\n",
    "\n",
    "# # Separando colunas de hh\n",
    "colunas_hh = [\n",
    "    col for col in colunas if col.startswith('hh')]\n",
    "\n",
    "# # Pegando apenas as colunas que nao sao de hh\n",
    "colunas_sem_hh = [col for col in colunas if not col.startswith('hh')]\n",
    "\n",
    "# # Definindo operacoes que serao aplicadas sobre as colunas\n",
    "dicionario_hh = {col: 'sum' for col in colunas_hh}\n",
    "dicionario_hh.update({col: 'first' for col in colunas_sem_hh})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGRUPAMENTO POR MES ANO LOCAL ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando por ano_mes, local e no_pessoa, igualmente operando sobre as outras colunas\n",
    "df_agrupado = df_expandido.groupby(\n",
    "    ['ano_mes', 'local_de_instalacao', 'no_pessoal']).agg(dicionario_hh).reset_index()\n",
    "df_agrupado.rename(columns={'hh_por_mes': 'hh_total'}, inplace=True)\n",
    "\n",
    "# Filtra para considerar apenas registros a partir de 2020-01\n",
    "df_agrupado = df_agrupado[df_agrupado['ano_mes'] >= '2020-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACRESCENTAR COLUNA PARA INDICAR SE TEVE OU NÃO ACIDENTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado['acidente'] = pd.NA\n",
    "\n",
    "df_agrupado.loc[df_agrupado['id_acidente'].notna(), 'acidente'] = 1\n",
    "df_agrupado.loc[df_agrupado['id_acidente'].isna(), 'acidente'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORTANDO DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.to_csv(pathUtil + \"dataset_treinamento.csv\",\n",
    "                   encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
