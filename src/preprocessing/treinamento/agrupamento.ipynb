{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agrupamento das linhas de operação associadas com acidentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lê o dataset com a associação entre Operações e Acidentes já feita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathUtil = ajuste_path('data/util/')\n",
    "df = pd.read_csv(pathUtil + 'dataset_associado.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guarda a data do acidente por conta do dia do acontecido que precisa ser readicionado posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_acidente_copia'] = df['data_acidente']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passa a data para datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_inicio'] = pd.to_datetime(df['data_inicio'])\n",
    "df['data_fim'] = pd.to_datetime(df['data_fim'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideia para agrupar as linhas de operação\n",
    "- Objetivo: reduzir o desbalanço entre linhas com e sem acidente.\n",
    "- Ideia: agrupar o trabalho feito por um funcionario em um mes em cada local\n",
    "- Caminho tomado: \n",
    "  - Criar novas linhas de operação para todas as operações que duram mais de um mês, e fazer com que cada linha represente um dos meses em que a operação esteve ativa; \n",
    "  - A partir do momento que todas as linhas representam um mês, pode-se usar um groupby com as chaves primárias sendo o conjunto [ano, mês, local de instalação, ID pessoal];\n",
    "  - No groupby, é necessário especificar como quer se agrupar cada coluna, as de HH fazem mais sentido somar, enquanto as de acidente faz mais sentido escolher a informação completa do primeiro acidente, pois é muito improvável que aconteça mais de um acidente com um mesma pessoa em um mesmo mês em um mesmo local;\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide a quantidade total de trabalho feita em uma operação para todos os meses em que ela esteve ativa, dividido igualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conta a quantidade de meses em que a operação esteve ativa\n",
    "df[\"meses\"] = (\n",
    "    (df[\"data_fim\"].dt.year - df[\"data_inicio\"].dt.year) * 12\n",
    "    + (df[\"data_fim\"].dt.month - df[\"data_inicio\"].dt.month)\n",
    ") + 1\n",
    "df[\"hh_por_mes\"] = df[\"hh\"] / df[\"meses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expansão das linhas de Operação para cada um dos meses em que esteve ativa\n",
    "\n",
    "Nesta seção, é criada uma função \n",
    "para cada linha do df que tenha a coluna meses > 1 são criadas novas linhas para representar cada mes.\n",
    "\n",
    "Exemplo da aplicação da função:\n",
    "|op         |data inicio    |data fim   |\n",
    "|-----------|---------------|-----------|\n",
    "|operacao1  |2022-02        |2022-04    |\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&darr;\n",
    "\n",
    "|op         |ano_mes    |\n",
    "|-----------|-----------|\n",
    "|operacao1  |2022-02    |\n",
    "|operacao1  |2022-03    |\n",
    "|operacao1  |2022-04    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expande_df(df):\n",
    "    '''\n",
    "    Para cada linha do df que tenha a coluna meses > 1\n",
    "    são criadas novas linhas para representar cada mes.\n",
    "\n",
    "    Exemplo:\n",
    "    |op         |data inicio    |data fim   |       |op         |ano_mes    |\n",
    "                                                    |operacao1  |2022-02    |\n",
    "    |operacao1  |2022-02        |2022-04    |   =>  |operacao1  |2022-03    |\n",
    "                                                    |operacao1  |2022-04    |\n",
    "    '''\n",
    "    # Gerar o espaço de tempo\n",
    "    espaco_de_tempo = pd.date_range(\n",
    "        start='2020-01-01', end=pd.Timestamp.now(), freq=\"MS\")\n",
    "    espaco_de_tempo = pd.DataFrame(\n",
    "        {'merge': [1]*len(espaco_de_tempo), 'ano_mes': espaco_de_tempo})\n",
    "    # Marcar operações que duram mais de um mês\n",
    "    df.loc[df['meses'] > 1, 'dura_mais_de_mes'] = 1\n",
    "\n",
    "    # Dropando colunas desnecessárias\n",
    "    colunas_a_dropar = [\"hh\"]\n",
    "    df = df.drop(columns=colunas_a_dropar)\n",
    "\n",
    "    # Expansão das operações que duram mais de um mês para todos os meses,\n",
    "    # mesmo os que não estava ativa a operação\n",
    "    df_expandido = pd.merge(df, espaco_de_tempo, left_on='dura_mais_de_mes',\n",
    "                            right_on='merge', how='left').drop(columns=['merge'])\n",
    "\n",
    "    # Tratamento das colunas de data para garantir o correto agrupamento\n",
    "    df_expandido['dura_mais_de_mes'] = df_expandido['dura_mais_de_mes'].fillna(\n",
    "        0)\n",
    "    df_expandido.loc[df_expandido['dura_mais_de_mes']\n",
    "                     == 0, 'ano_mes'] = df_expandido['data_fim']\n",
    "    df_expandido['ano_mes'] = df_expandido['ano_mes'].dt.to_period('M')\n",
    "    df_expandido['data_inicio'] = df_expandido['data_inicio'].dt.to_period('M')\n",
    "    df_expandido['data_fim'] = df_expandido['data_fim'].dt.to_period('M')\n",
    "    df_expandido['data_acidente'] = pd.to_datetime(\n",
    "        df_expandido['data_acidente'])\n",
    "    df_expandido['data_acidente'] = df_expandido['data_acidente'].dt.to_period(\n",
    "        'M')\n",
    "\n",
    "    # Eliminar linhas onde a operação não estava ativa\n",
    "    df_expandido = df_expandido[(df_expandido['ano_mes'] >= df_expandido['data_inicio']) &\n",
    "                                (df_expandido['ano_mes'] <= df_expandido['data_fim'])]\n",
    "    return df_expandido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expandido = expande_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faz a contagem do HH para cada categoria de txt.breve_operacao e cada categoria de denominacao_tam\n",
    "\n",
    "Os valores do HH de cada tipo são adicionados em colunas novas, para que no agrupamento consiga-se manter esta informação em uma mesma linha;\n",
    "\n",
    "Desta maneira, ao final do agrupamento se terá uma linha como por o seguinte exemplo:\n",
    "\n",
    "|funcionário |ano    |mês|local de instalação    |HH total   |HH serviço |HH relatório   |HH PLANEJADA   |HH MELHORIA|\n",
    "|------------|-------|---|-----------------------|-----------|-----------|---------------|---------------|-----------|\n",
    "|1000001     |2023   |06 |S-S-ARE                |120        |80         |40             |120            |0          |\n",
    "\n",
    "A soma de todo o HH das categorias de txt.breve_operacao será sempre igual ao HH total, assim como o HH de todas as categorias de denominacao_tam somadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_tipo_atividade = [\"txt.breve_operacao\", \"denominacao_tam\"]\n",
    "\n",
    "# separar colunas de acidente apenas\n",
    "lista_colunas_acidentes = df_expandido.columns[df_expandido.columns.str.contains(\n",
    "    'acidente')].tolist()\n",
    "\n",
    "# Colocar NAN nas colunas da acidente para as linhas em a data de acidente nao bate com a data da operação\n",
    "df_expandido.loc[(df_expandido['data_acidente'] != pd.NA) & (\n",
    "    df_expandido['ano_mes'] != df_expandido['data_acidente']), lista_colunas_acidentes] = pd.NA\n",
    "\n",
    "\n",
    "# Para cada categoria de atividade, criar uma nova coluna para armazenar o HH dessa categoria\n",
    "for coluna_tipo_atividade in colunas_tipo_atividade:\n",
    "    for atividade in df_expandido[coluna_tipo_atividade].unique():\n",
    "        # trata a exceção de haver categorias com o mesmo nome em colunas diferentes\n",
    "        if \"hh_de_\" + atividade in df_expandido.columns:\n",
    "            df_expandido.loc[df_expandido[coluna_tipo_atividade] == atividade,\n",
    "                             \"hh_de_\" + atividade + \"_de_\" + coluna_tipo_atividade] = df_expandido[\"hh_por_mes\"]\n",
    "        else:  # adiciona à sua propria coluna o hh desta categoria de atividade\n",
    "            df_expandido.loc[df_expandido[coluna_tipo_atividade] == atividade,\n",
    "                             \"hh_de_\" + atividade] = df_expandido[\"hh_por_mes\"]\n",
    "\n",
    "df_expandido.drop(columns=['txt.breve_operacao',\n",
    "                  'tam', 'denominacao_tam'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do dicionário para ser usado no groupby\n",
    "Este dicionário especifica o que acontece com cada coluna do dataset, com algumas sendo a soma do total dos valores que aparecem na coluna, e outras sendo o primeiro valor pois só é suposto haver um valor para estas colunas em cada chave primária.\n",
    "\n",
    "Atualmente apenas as colunas de HH precisam de um tratamento diferente de pegar apenas o primeiro valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dicionario, indicando qual operação será efetuada sobre quais colunas durante o agrupamento\n",
    "\n",
    "# Retirando as colunas que são as variáveis do groupby da lista do dicionário\n",
    "colunas = list(df_expandido.columns)\n",
    "colunas.remove(\"no_pessoal\")\n",
    "colunas.remove(\"local_de_instalacao\")\n",
    "colunas.remove(\"ano_mes\")\n",
    "\n",
    "# Separando colunas de hh\n",
    "colunas_hh = [\n",
    "    col for col in colunas if col.startswith('hh')]\n",
    "\n",
    "# Pegando apenas as colunas que nao sao de hh\n",
    "colunas_sem_hh = [col for col in colunas if not col.startswith('hh')]\n",
    "\n",
    "# Definindo operacoes que serao aplicadas sobre as colunas\n",
    "dicionario_hh = {col: 'sum' for col in colunas_hh}\n",
    "dicionario_hh.update({col: 'first' for col in colunas_sem_hh})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupamento por mês, ano, local e id como chave primária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupando por ano_mes, local e no_pessoa, igualmente operando sobre as outras colunas\n",
    "df_agrupado = df_expandido.groupby(\n",
    "    ['ano_mes', 'local_de_instalacao', 'no_pessoal']).agg(dicionario_hh).reset_index()\n",
    "\n",
    "# após o groupby a coluna hh_por_mes agora tem os valores das diferentes operações todas somadas\n",
    "df_agrupado.rename(columns={'hh_por_mes': 'hh_total'}, inplace=True)\n",
    "\n",
    "# Filtra para considerar apenas registros a partir de 2020-01\n",
    "df_agrupado = df_agrupado[df_agrupado['ano_mes'] >= '2020-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acrescentar coluna para indicar se teve ou não acidente para facilitar a análise do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado['acidente'] = pd.NA  # cria a coluna\n",
    "\n",
    "df_agrupado.loc[df_agrupado['id_acidente'].notna(), 'acidente'] = 1\n",
    "df_agrupado.loc[df_agrupado['id_acidente'].isna(), 'acidente'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaura a coluna data do acidente para recuperar o dia em que ele ocorreu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.drop(columns={'data_acidente'}, axis=1, inplace=True)\n",
    "df_agrupado.rename(\n",
    "    columns={'data_acidente_copia': 'data_acidente'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exportando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.to_csv(pathUtil + \"dataset_treinamento.csv\",\n",
    "                   encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
