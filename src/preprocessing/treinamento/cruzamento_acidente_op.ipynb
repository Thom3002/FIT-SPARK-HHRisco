{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathUtil = ajuste_path('data/util/')\n",
    "pathInput = ajuste_path('data/input/')\n",
    "\n",
    "df_acid = pd.read_csv(\n",
    "    pathUtil + 'acidentes/acidentes_preparado.csv', encoding='utf-8', sep='#')\n",
    "\n",
    "df_op = pd.read_csv(\n",
    "    pathUtil + 'os/operacoes_preparado.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_os = list(df_op.columns)\n",
    "colunas_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op['data_inicio'] = pd.to_datetime(df_op['data_inicio'])\n",
    "df_op['data_fim'] = pd.to_datetime(df_op['data_fim'])\n",
    "df_op['data_fim'] = df_op['data_fim'] + pd.Timedelta(days=1)\n",
    "df_op.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_acid = df_acid.columns\n",
    "colunas_acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acid['data'] = pd.to_datetime(df_acid['data'])\n",
    "df_acid['id'] = df_acid['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op['merge'] = False\n",
    "\n",
    "colunas_os.append('merge')\n",
    "\n",
    "colunas_acidente_na_op = set()\n",
    "colunas_correto = set()\n",
    "\n",
    "for idx, row in df_acid.iterrows():\n",
    "\n",
    "    df_op.loc[\n",
    "        ((df_op['data_inicio'] <= row['data'])\n",
    "         & (df_op['data_fim'] > row['data']))  # mesma data\n",
    "        & (df_op['no_pessoal'] == row['id']),  # mesma matricula\n",
    "        'merge'\n",
    "    ] = True\n",
    "\n",
    "    if df_op[df_op['merge']].shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    if 'id_acidente' not in colunas_acidente_na_op:\n",
    "        for key in row.index:\n",
    "            colunas_acidente_na_op.add(key + '_acidente')\n",
    "            df_op.loc[df_op['merge'], key + '_acidente'] = row[key]\n",
    "\n",
    "        df_op[list(colunas_acidente_na_op)] = df_op[list(\n",
    "            colunas_acidente_na_op)].astype(object)\n",
    "        continue\n",
    "\n",
    "    if df_op.loc[df_op['merge'], 'id_acidente'].isna().all():\n",
    "        for key in row.index:\n",
    "            colunas_acidente_na_op.add(key + '_acidente')\n",
    "            df_op.loc[df_op['merge'], key + '_acidente'] = row[key]\n",
    "    else:\n",
    "        df_duplicatas = df_op.loc[df_op['merge'], colunas_os].reset_index()\n",
    "        lim_sup = len(df_op)\n",
    "        df_duplicatas.index = df_duplicatas.index + lim_sup + 1\n",
    "        df_op = pd.concat([df_op, df_duplicatas], axis=0)\n",
    "        df_op.loc[:lim_sup, 'merge'] = False\n",
    "\n",
    "        for key in row.index:\n",
    "            colunas_acidente_na_op.add(key + '_acidente')\n",
    "            df_op.loc[df_op['merge'], key + '_acidente'] = row[key]\n",
    "\n",
    "    df_op['merge'] = False\n",
    "\n",
    "col_float = ['potencial_acidente',\n",
    "             'latitude_acidente',\n",
    "             'longitude_acidente',\n",
    "             'id_acidente',\n",
    "             ]\n",
    "\n",
    "col_datetime = ['data_acidente']\n",
    "\n",
    "df_op[col_float] = df_op[col_float].astype(float)\n",
    "\n",
    "for col in col_datetime:\n",
    "    df_op[col] = pd.to_datetime(df_op[col])\n",
    "\n",
    "df_op.drop(columns=['merge', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_op['descricao_do_acidente'] = df_op['descricao_do_acidente'].apply(\n",
    "#     lambda x: x.replace(',', '.') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_associacao = pd.read_csv(\n",
    "    pathInput + \"associa_acidentes_operacao_coordenadas_confianca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_associacao.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In column 'confianca', change values from 0,5 to float 0.5, if it is a string\n",
    "df_associacao['Confianca'] = df_associacao['Confianca'].apply(\n",
    "    lambda x: float(x.replace(',', '.')) if isinstance(x, str) else x)\n",
    "\n",
    "df_associacao['Confianca'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_associacao = df_associacao[df_associacao['Confianca'] > 0]\n",
    "# adicionar escolha pelo maior contador dentre as ops\n",
    "for idx, row in df_associacao.iterrows():\n",
    "    ordem = row['Ordem']\n",
    "    op = row['Operação']\n",
    "    id = row['ID']\n",
    "    data = row['Dt']\n",
    "\n",
    "    mask = ((df_op['ordem'] == ordem)\n",
    "            & (df_op['operacao'] == op)\n",
    "            & (df_op['no_pessoal'] == id)\n",
    "            & ((df_op['data_inicio'] <= data)\n",
    "               & (df_op['data_fim'] > data))\n",
    "            )\n",
    "\n",
    "    ops_ativas = df_op.loc[mask]\n",
    "    if ops_ativas.shape[0] > 1:\n",
    "        ultimo_lancamento = ops_ativas['contador'].max()\n",
    "        mask = (df_op['contador'] == ultimo_lancamento) & mask\n",
    "    for key in row.index:\n",
    "        colunas_correto.add(key.lower() + '_correto')\n",
    "        df_op.loc[mask, key.lower() + '_correto'] = row[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazer testes para certificar onde e como '_correto' diferencia do '_acidente'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_op[df_op['id_correto'].notna() | df_op['id_acidente'].notna()]\n",
    "\n",
    "df_acidentes_possivel_errados = df_teste[df_teste['id_correto'].isna(\n",
    ") & df_teste['id_acidente'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigindo a associação a partir do link feit à mão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.loc[df_op['id_correto'].isna(),\n",
    "          list(colunas_acidente_na_op)] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op['desc_acid'] = df_op['descricao_acidente'].str.strip().str[:20]\n",
    "df_op['desc_corr'] = df_op['descrição_correto'].str.strip().str[:20]\n",
    "df_op['diferente'] = False\n",
    "df_op.loc[df_op['desc_acid'] != df_op['desc_corr'], 'diferente'] = True\n",
    "df_op.loc[df_op['id_acidente'].isna(), 'diferente'] = False\n",
    "df_op.fillna({'diferente': False}, inplace=True)\n",
    "\n",
    "df_op = df_op[~df_op['diferente']]\n",
    "\n",
    "cols_intermediarias = ['desc_acid', 'desc_corr', 'diferente']\n",
    "df_op.drop(columns=cols_intermediarias, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_op[df_op['id_correto'].notna() | df_op['id_acidente'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.drop(columns=colunas_correto, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.to_csv(pathUtil + 'dataset_associado.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
