{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# União das tabelas de Operações e de Acidentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura das tabelas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathUtil = ajuste_path('data/util/')\n",
    "pathInput = ajuste_path('data/input/')\n",
    "\n",
    "df_acid = pd.read_csv(\n",
    "    pathUtil + 'acidentes/acidentes_preparado.csv', encoding='utf-8', sep='#')\n",
    "\n",
    "df_op = pd.read_csv(\n",
    "    pathUtil + 'os/operacoes_preparado.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando o nome das colunas para uso posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_os = list(df_op.columns)\n",
    "colunas_acid = df_acid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traduz o tipo das colunas lidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acid['data'] = pd.to_datetime(df_acid['data'])\n",
    "df_acid['id'] = df_acid['id'].astype(int)\n",
    "\n",
    "df_op['data_inicio'] = pd.to_datetime(df_op['data_inicio'])\n",
    "df_op['data_fim'] = pd.to_datetime(df_op['data_fim'])\n",
    "# necessário adicionar um dia pois a data de operação não inclui a hora\n",
    "# enquanto o acidente sim\n",
    "df_op['data_fim'] = df_op['data_fim'] + pd.Timedelta(days=1)\n",
    "df_op.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associação dos acidentes com as operações que estavam ativas no dia do acidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op['merge'] = False\n",
    "\n",
    "colunas_os.append('merge')\n",
    "\n",
    "# cria um set que não permite repetição para\n",
    "# guardar quais foram as colunas já adicionadas\n",
    "colunas_acidente_na_op = set()\n",
    "\n",
    "# adiciona cada acidente a todas as operações\n",
    "# ativas daquele funcionário,\n",
    "# com a intenção de depois filtrar\n",
    "# qual a operação correta\n",
    "for idx, row in df_acid.iterrows():\n",
    "\n",
    "    df_op.loc[\n",
    "        ((df_op['data_inicio'] <= row['data'])\n",
    "         & (df_op['data_fim'] > row['data']))  # mesma data\n",
    "        & (df_op['no_pessoal'] == row['id']),  # mesma matricula\n",
    "        'merge'\n",
    "    ] = True  # assim guarda quais são as linhas a serem associadas\n",
    "\n",
    "    if df_op[df_op['merge']].shape[0] == 0:\n",
    "        continue  # se não há operações, pula o acidente\n",
    "\n",
    "    if 'id_acidente' not in colunas_acidente_na_op:\n",
    "        # primeira adição de colunas\n",
    "        for key in row.index:\n",
    "            colunas_acidente_na_op.add(key + '_acidente')\n",
    "            df_op.loc[df_op['merge'], key + '_acidente'] = row[key]\n",
    "\n",
    "        df_op[list(colunas_acidente_na_op)] = df_op[list(\n",
    "            colunas_acidente_na_op)].astype(object)\n",
    "        continue\n",
    "\n",
    "    if df_op.loc[df_op['merge'], 'id_acidente'].isna().all():\n",
    "        # caso onde todas as operações ativas não causaram nenhum acidente\n",
    "        for key in row.index:\n",
    "            colunas_acidente_na_op.add(key + '_acidente')\n",
    "            df_op.loc[df_op['merge'], key + '_acidente'] = row[key]\n",
    "\n",
    "    else:\n",
    "        # caso onde alguma operação já causou algum outro acidente\n",
    "        # adiciona-se ao final a operação duplicada com o novo\n",
    "        # acidente associado, com a intenção de que isto será\n",
    "        # limpado no momento de filtrar as associações corretas\n",
    "        df_duplicatas = df_op.loc[df_op['merge'], colunas_os].reset_index()\n",
    "        lim_sup = len(df_op)\n",
    "        df_duplicatas.index = df_duplicatas.index + lim_sup + 1\n",
    "        df_op = pd.concat([df_op, df_duplicatas], axis=0)\n",
    "        df_op.loc[:lim_sup, 'merge'] = False\n",
    "\n",
    "        for key in row.index:\n",
    "            colunas_acidente_na_op.add(key + '_acidente')\n",
    "            df_op.loc[df_op['merge'], key + '_acidente'] = row[key]\n",
    "\n",
    "    df_op['merge'] = False  # limpa as operações para a nova iteração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpa o resultado da associação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_float = ['potencial_acidente',\n",
    "             'latitude_acidente',\n",
    "             'longitude_acidente',\n",
    "             'id_acidente',\n",
    "             ]\n",
    "\n",
    "col_datetime = ['data_acidente']\n",
    "\n",
    "df_op[col_float] = df_op[col_float].astype(float)\n",
    "\n",
    "for col in col_datetime:\n",
    "    df_op[col] = pd.to_datetime(df_op[col])\n",
    "\n",
    "df_op.drop(columns=['merge', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lê o arquivo onde foi guardada a associação escolhida à mão \n",
    "Análise compreensiva feita a partir da associação inicial apenas através da data\n",
    "\n",
    "Foram analisados diversos fatores para a associação como a descrição do acidente,\n",
    "o txt. breve da operação, o local de instalação, a coordenada do acidente, a duração\n",
    "da operação, a proximidade de datas, a quantidade de trabalho entre outros ainda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_associacao = pd.read_csv(\n",
    "    pathInput + \"associa_acidentes_operacao_coordenadas_confianca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_associacao.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessa a coluna confiança\n",
    "A coluna 'Confianca' representa a associação escolhida à mão, para os casos positivos. O valor indica parcialmente a confiança da escolha por aquela ser a operação que causou o acidente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_associacao['Confianca'] = df_associacao['Confianca'].apply(\n",
    "    lambda x: float(x.replace(',', '.')) if isinstance(x, str) else x)\n",
    "\n",
    "df_associacao['Confianca'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adiciona ao DataFrame as informações da associação à mão\n",
    "usa-se de sufixo '_correto' para indicar as informações provenientes da associação à mão (escolhido por ser a associação mais \"correta\" do que a feita automaticamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_associacao = df_associacao[df_associacao['Confianca'] > 0]\n",
    "\n",
    "# guardar os nomes das colunas da associacao a mao univocamente\n",
    "colunas_correto = set()\n",
    "\n",
    "# realiza a adição\n",
    "for idx, row in df_associacao.iterrows():\n",
    "    # informacoes a serem usadas para achar qual foi a associacao escolhida\n",
    "    ordem = row['Ordem']\n",
    "    op = row['Operação']\n",
    "    id = row['ID']\n",
    "    data = row['Dt']\n",
    "\n",
    "    mask = ((df_op['ordem'] == ordem)\n",
    "            & (df_op['operacao'] == op)\n",
    "            & (df_op['no_pessoal'] == id)\n",
    "            & ((df_op['data_inicio'] <= data)\n",
    "               & (df_op['data_fim'] > data))\n",
    "            )\n",
    "\n",
    "    ops_ativas = df_op.loc[mask]\n",
    "    if ops_ativas.shape[0] > 1:\n",
    "        # caso onde houve mais de uma confirmação de uma operação com um mesmo funcionário\n",
    "        # se escolhe o lançamento mais recente\n",
    "        ultimo_lancamento = ops_ativas['contador'].max()\n",
    "        mask = (df_op['contador'] == ultimo_lancamento) & mask\n",
    "    for key in row.index:\n",
    "        colunas_correto.add(key.lower() + '_correto')\n",
    "        df_op.loc[mask, key.lower() + '_correto'] = row[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazer testes para certificar onde e como '_correto' diferencia do '_acidente'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_op[df_op['id_correto'].notna() | df_op['id_acidente'].notna()]\n",
    "\n",
    "df_acidentes_possivel_errados = df_teste[df_teste['id_correto'].isna(\n",
    ") & df_teste['id_acidente'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrigindo a associação a partir do link feito à mão\n",
    "Despopula-se os campos onde estava uma associação não 'correta'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.loc[df_op['id_correto'].isna(),\n",
    "          list(colunas_acidente_na_op)] = pd.NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza das operações duplicadas, deixando cada uma com um acidente\n",
    "Limpeza feita através da descrição pois para estes casos existem as linhas duplicadas de duas operações as duas operações associadas em cada linha a um dos dois acidentes, após a operação se tem cada operação com um acidente, conforme o exemplo:\n",
    "\n",
    "operação1 <=> acidente1\n",
    "\n",
    "operação2 <=> acidente1\n",
    "\n",
    "operação1 <=> acidente2\n",
    "\n",
    "operação2 <=> acidente2\n",
    "\n",
    "se torna \n",
    "\n",
    "operação1 <=> acidente1\n",
    "\n",
    "operação2 <=> acidente2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# já foram usadas as outras informações que vieram do _correto,\n",
    "# mas se viessem mais informações poderia não ser utilizada a\n",
    "# descrição para discriminar qual foi o verdadeiro acidente causado.\n",
    "# Recomenda-se em futuras associações à mão que se inclua mais colunas\n",
    "# que de preferência tenha valores únicos.\n",
    "df_op['desc_acid'] = df_op['descricao_acidente'].str.strip().str[:20]\n",
    "df_op['desc_corr'] = df_op['descrição_correto'].str.strip().str[:20]\n",
    "df_op['diferente'] = False\n",
    "df_op.loc[df_op['desc_acid'] != df_op['desc_corr'], 'diferente'] = True\n",
    "df_op.loc[df_op['id_acidente'].isna(), 'diferente'] = False\n",
    "df_op.fillna({'diferente': False}, inplace=True)\n",
    "\n",
    "df_op = df_op[~df_op['diferente']]\n",
    "\n",
    "cols_intermediarias = ['desc_acid', 'desc_corr', 'diferente']\n",
    "df_op.drop(columns=cols_intermediarias, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame para fazer a comparação entre a associação automática e a feita à mão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = df_op[df_op['id_correto'].notna() | df_op['id_acidente'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove as colunas adicionadas puramente para a associação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.drop(columns=colunas_correto, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_op.to_csv(pathUtil + 'dataset_associado.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
