{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORTAR AS PLANILHAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from resolve_path import ajuste_path, read_input\n",
    "\n",
    "# # Para pegar os dados da API da Open Meteo (comentado para nao pesar a pipeline)\n",
    "# import time\n",
    "# import openmeteo_requests\n",
    "# import requests_cache\n",
    "# from openmeteo_requests import Client\n",
    "# from retry_requests import retry\n",
    "# import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IMPORTANDO PLANILHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_iw = \"data/util/os/\"\n",
    "\n",
    "path_iw = ajuste_path(path_iw)\n",
    "\n",
    "df_iw47 = pd.read_csv(path_iw + \"IW47_Executadas_preparado.csv\")\n",
    "\n",
    "df_iw47.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iw47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_tipo_atividade = [\"Txt.breve operação\", \"Denominação TAM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iw47[\"Data fim\"] = pd.to_datetime(df_iw47[\"Data fim\"])\n",
    "df_iw47[\"Data inicio\"] = pd.to_datetime(df_iw47[\"Data inicio\"])\n",
    "df_iw47[\"Local de instalação\"] = df_iw47[\"Local de instalação\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CRIANDO DATAFRAME SEM INCLUIR DATAS FINAIS ANTERIORES A DATAS INICIAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas onde a data final é superior a data inicial\n",
    "df_sem_linhas_irregulares = df_iw47.loc[df_iw47[\"Data fim\"]\n",
    "                                        >= df_iw47[\"Data inicio\"]]\n",
    "\n",
    "num_linhas_removidas = df_iw47.shape[0] - df_sem_linhas_irregulares.shape[0]\n",
    "print(\"Linhas removidas:\", num_linhas_removidas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FUNÇÃO QUE ADD COLUNA DE HH POR MES E QUANTIDADE DE MESES PASSADOS DURANTE A OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soma dos meses, em funcao da quantidade de anos que se passaram e meses, entre o inicio e fim da OS\n",
    "df = df_sem_linhas_irregulares\n",
    "\n",
    "df[\"Meses\"] = (\n",
    "    (df[\"Data fim\"].dt.year - df[\"Data inicio\"].dt.year) * 12\n",
    "    + (df[\"Data fim\"].dt.month - df[\"Data inicio\"].dt.month)\n",
    ") + 1\n",
    "df[\"HH por mes\"] = df[\"HH final\"] / df[\"Meses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ADICIONANDO DURAÇÃO DA OS ANTES DE AGRUPAR PARA MAIOR ACURÁCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que as colunas 'Data inicio' e 'Data fim' já estão no formato datetime64\n",
    "df['Data inicio'] = pd.to_datetime(df['Data inicio'])\n",
    "df['Data fim'] = pd.to_datetime(df['Data fim'])\n",
    "\n",
    "# Criar uma condição para verificar se a Data fim é 2020 ou mais recente e Data inicio é 2019 ou anterior\n",
    "condicao = (df['Data fim'] >= pd.Timestamp('2020-01-01')\n",
    "            ) & (df['Data inicio'] < pd.Timestamp('2020-01-01'))\n",
    "\n",
    "# Aplicar a condição para ajustar a Data inicio\n",
    "df.loc[condicao, 'Data inicio'] = pd.Timestamp('2020-01-01')\n",
    "\n",
    "# Calcular a duração em dias úteis e multiplicar por 8 para horas\n",
    "df['Duração'] = (np.busday_count(df['Data inicio'].values.astype('datetime64[D]'),\n",
    "                                 # 8 horas por dia\n",
    "                                 df['Data fim'].values.astype('datetime64[D]')) + 1)*8\n",
    "\n",
    "# Calcular a quantidade de meses após 2020 visto que mudamos a data de inicio\n",
    "df['Meses após 2020'] = (df['Data fim'].dt.year - df['Data inicio'].dt.year) * \\\n",
    "    12 + (df['Data fim'].dt.month - df['Data inicio'].dt.month + 1)\n",
    "\n",
    "# Calcular a duração em meses\n",
    "df['Duração'] = df['Duração'] / df['Meses após 2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FUNCAO QUE AGRUPA HH POR ANO, MES, LOCAL E TIPO DE ATIVIDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Data inicio\"] = df[\"Data inicio\"].apply(lambda x: x.replace(day=1))\n",
    "df[\"Data fim\"] = df[\"Data fim\"].apply(lambda x: x.replace(day=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar o espaço de tempo\n",
    "espaco_de_tempo = pd.date_range(\n",
    "    start='2020-01-01', end=pd.Timestamp.now(), freq=\"MS\")\n",
    "espaco_de_tempo = pd.DataFrame(\n",
    "    {'merge': [1]*len(espaco_de_tempo), 'Ano Mes': espaco_de_tempo})\n",
    "\n",
    "# Marcar operações que duram mais de um mês\n",
    "df.loc[df['Meses'] > 1, 'dura mais de mes'] = 1\n",
    "\n",
    "# Manter apenas as colunas necessárias\n",
    "colunas_a_manter = [\n",
    "    'Local de instalação',\n",
    "    'Latitude',\n",
    "    'Longitude',\n",
    "    'HH por mes',\n",
    "    'Meses',\n",
    "    'dura mais de mes',\n",
    "    'Data inicio',\n",
    "    'Data fim',\n",
    "    'Duração'\n",
    "]\n",
    "colunas_a_manter.extend(colunas_tipo_atividade)\n",
    "df = df[colunas_a_manter]\n",
    "\n",
    "# Expansão das operações que duram mais de um mês\n",
    "df_expandido = pd.merge(df, espaco_de_tempo, left_on='dura mais de mes',\n",
    "                        right_on='merge', how='left').drop(columns=['merge'])\n",
    "\n",
    "# Tratamento das colunas de data para garantir o correto agrupamento\n",
    "df_expandido['dura mais de mes'] = df_expandido['dura mais de mes'].fillna(0)\n",
    "df_expandido.loc[df_expandido['dura mais de mes']\n",
    "                 == 0, 'Ano Mes'] = df_expandido['Data fim']\n",
    "df_expandido['Ano Mes'] = df_expandido['Ano Mes'].dt.to_period('M')\n",
    "df_expandido['Data inicio'] = df_expandido['Data inicio'].dt.to_period('M')\n",
    "df_expandido['Data fim'] = df_expandido['Data fim'].dt.to_period('M')\n",
    "\n",
    "# Eliminar linhas onde a operação não estava ativa\n",
    "df_expandido = df_expandido[(df_expandido['Ano Mes'] >= df_expandido['Data inicio']) &\n",
    "                            (df_expandido['Ano Mes'] <= df_expandido['Data fim'])]\n",
    "\n",
    "# Manter apenas as colunas necessárias para o agrupamento final\n",
    "colunas_a_manter = ['Ano Mes', 'Local de instalação',\n",
    "                    'Latitude', 'Longitude', 'HH por mes', 'Duração']\n",
    "colunas_a_manter.extend(colunas_tipo_atividade)\n",
    "df_expandido = df_expandido[colunas_a_manter]\n",
    "\n",
    "# Para cada categoria de atividade, criar uma nova coluna para armazenar o HH dessa categoria\n",
    "for coluna_tipo_atividade in colunas_tipo_atividade:\n",
    "    for atividade in df_expandido[coluna_tipo_atividade].unique():\n",
    "        if \"HH de \" + atividade in df_expandido.columns:\n",
    "            df_expandido.loc[df_expandido[coluna_tipo_atividade] == atividade,\n",
    "                             \"HH de \" + atividade + \" de \" + coluna_tipo_atividade] = df_expandido[\"HH por mes\"]\n",
    "        else:\n",
    "            df_expandido.loc[df_expandido[coluna_tipo_atividade] == atividade,\n",
    "                             \"HH de \" + atividade] = df_expandido[\"HH por mes\"]\n",
    "\n",
    "# Limpa colunas desnecessárias após o agrupamento\n",
    "df_agrupado = df_expandido.groupby(\n",
    "    ['Ano Mes', 'Local de instalação']).sum().reset_index()\n",
    "df_agrupado.drop(columns=colunas_tipo_atividade, inplace=True)\n",
    "df_agrupado.rename(columns={'HH por mes': 'HH total'}, inplace=True)\n",
    "\n",
    "# Filtra para considerar apenas registros a partir de 2020-01\n",
    "df_agrupado = df_agrupado[df_agrupado['Ano Mes'] >= '2020-01']\n",
    "\n",
    "\n",
    "for li in df_agrupado[\"Local de instalação\"].unique():\n",
    "    df_agrupado.loc[df_agrupado['Local de instalação'] == li,\n",
    "                    'Latitude'] = df_expandido.loc[df_expandido['Local de instalação'] == li, 'Latitude'].values[0]\n",
    "    df_agrupado.loc[df_agrupado['Local de instalação'] == li,\n",
    "                    'Longitude'] = df_expandido.loc[df_expandido['Local de instalação'] == li, 'Longitude'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRATAMENTO FINAL PARA PODER EXPORTAR A TABELA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = df_agrupado.sort_values(\n",
    "    by=[\"Ano Mes\", \"Local de instalação\"]).reset_index(drop=True)\n",
    "\n",
    "df_agrupado.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando Colunas Metereologicas no Dataset de OS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Função de retry personalizada\n",
    "# def retry(session, retries=5, backoff_factor=0.2):\n",
    "#     def wrapped_request(method, url, **kwargs):\n",
    "#         for attempt in range(retries):\n",
    "#             try:\n",
    "#                 response = session.request(method, url, **kwargs)\n",
    "#                 response.raise_for_status()  # Levanta um erro se o status não for 200\n",
    "#                 return response\n",
    "#             except requests.exceptions.RequestException as e:\n",
    "#                 if attempt == retries - 1:\n",
    "#                     raise\n",
    "#                 time.sleep(backoff_factor * (2 ** attempt))\n",
    "#     return wrapped_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import requests_cache\n",
    "# from openmeteo_requests import Client\n",
    "\n",
    "# # Configurar a sessão da API com cache\n",
    "# cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "# openmeteo = Client(session=cache_session)\n",
    "\n",
    "# # Preparar um DataFrame para armazenar os resultados\n",
    "# resultados = []\n",
    "\n",
    "# # Iterar sobre cada linha do df_agrupado\n",
    "# for index, row in df_agrupado.iterrows():\n",
    "#     # Converter a coluna 'Ano Mes' para string\n",
    "#     ano_mes = str(row['Ano Mes'])\n",
    "\n",
    "#     # Dividir a string em ano e mês usando o espaço\n",
    "#     ano, mes = ano_mes.split(\"-\")\n",
    "#     latitude = row['Latitude']\n",
    "#     longitude = row['Longitude']\n",
    "\n",
    "#     # Definir a data de início e fim do mês\n",
    "#     start_date = f\"{ano}-{mes}-01\"\n",
    "#     end_date = f\"{ano}-{mes}-{pd.Period(start_date).days_in_month}\"\n",
    "\n",
    "#     # Parâmetros para a solicitação da API\n",
    "#     params = {\n",
    "#         \"latitude\": latitude,\n",
    "#         \"longitude\": longitude,\n",
    "#         \"start_date\": start_date,\n",
    "#         \"end_date\": end_date,\n",
    "#         \"daily\": [\n",
    "#             \"weather_code\", \"temperature_2m_max\", \"temperature_2m_min\", \"temperature_2m_mean\",\n",
    "#             \"precipitation_sum\", \"rain_sum\", \"precipitation_hours\",\n",
    "#             \"wind_speed_10m_max\", \"wind_gusts_10m_max\"\n",
    "#         ],\n",
    "#         \"timezone\": \"America/Sao_Paulo\"\n",
    "#     }\n",
    "\n",
    "#     # Solicitar dados à API\n",
    "#     try:\n",
    "#         response = openmeteo.weather_api(\"https://archive-api.open-meteo.com/v1/archive\", params=params)[0]\n",
    "\n",
    "#         # Processamento dos dados diários\n",
    "#         daily = response.Daily()\n",
    "#         daily_data = {\n",
    "#             \"date\": pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "#             \"weather_code\": daily.Variables(0).ValuesAsNumpy(),\n",
    "#             \"temperature_2m_max\": daily.Variables(1).ValuesAsNumpy(),\n",
    "#             \"temperature_2m_min\": daily.Variables(2).ValuesAsNumpy(),\n",
    "#             \"temperature_2m_mean\": daily.Variables(3).ValuesAsNumpy(),\n",
    "#             \"precipitation_sum\": daily.Variables(4).ValuesAsNumpy(),\n",
    "#             \"rain_sum\": daily.Variables(5).ValuesAsNumpy(),\n",
    "#             \"precipitation_hours\": daily.Variables(6).ValuesAsNumpy(),\n",
    "#             \"wind_speed_10m_max\": daily.Variables(7).ValuesAsNumpy(),\n",
    "#             \"wind_gusts_10m_max\": daily.Variables(8).ValuesAsNumpy(),\n",
    "#         }\n",
    "\n",
    "#         daily_dataframe = pd.DataFrame(data=daily_data)\n",
    "\n",
    "#         # Calcular as médias das variáveis meteorológicas para o mês\n",
    "#         monthly_averages = daily_dataframe.mean()\n",
    "\n",
    "#         # Adicionar os resultados ao DataFrame final\n",
    "#         resultados.append({\n",
    "#             \"Ano-Mes\": ano_mes,\n",
    "#             \"Local de instalação\": row['Local de instalação'],\n",
    "#             \"Latitude\": latitude,\n",
    "#             \"Longitude\": longitude,\n",
    "#             \"HH total\": row['HH total'],\n",
    "#             \"Temp_Max\": monthly_averages['temperature_2m_max'],\n",
    "#             \"Temp_Min\": monthly_averages['temperature_2m_min'],\n",
    "#             \"Temp_Mean\": monthly_averages['temperature_2m_mean'],\n",
    "#             \"Precipitation_Sum\": monthly_averages['precipitation_sum'],\n",
    "#             \"Rain_Sum\": monthly_averages['rain_sum'],\n",
    "#             \"Precipitation_Hours\": monthly_averages['precipitation_hours'],\n",
    "#             \"Wind_Speed_Max\": monthly_averages['wind_speed_10m_max'],\n",
    "#             \"Wind_Gusts_Max\": monthly_averages['wind_gusts_10m_max']\n",
    "#         })\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Erro ao solicitar dados da API para {row['Local de instalação']} em {ano_mes}: {e}\")\n",
    "\n",
    "# # Converter a lista de resultados para um DataFrame\n",
    "# df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# # Exportar para um arquivo CSV (opcional)\n",
    "# # df_resultados.to_csv(\"resultados_meteorologicos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer uma funcao q faz a api continuar de onde parou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_resultados.to_csv(path_iw + \"resultados_metereologicos_incompletos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Carregar os resultados incompletos e o dataframe de treinamento\n",
    "# df_resultados = pd.read_csv(path_iw + \"resultados_metereologicos_incompletos.csv\")\n",
    "# df_agrupado = pd.read_csv(path_iw + \"os_treinamento.csv\")\n",
    "\n",
    "# # Criar uma coluna de chave em ambos os DataFrames para comparação\n",
    "# df_resultados['chave'] = df_resultados['Local de instalação'] + '-' + df_resultados['Ano-Mes']\n",
    "# df_agrupado['chave'] = df_agrupado['Local de instalação'] + '-' + df_agrupado['Ano Mes'].astype(str)\n",
    "\n",
    "# # Verificar quais registros já foram processados\n",
    "# processados = df_resultados['chave'].tolist()\n",
    "\n",
    "# # Filtrar o df_agrupado para pegar apenas as linhas que ainda não foram processadas\n",
    "# faltantes = df_agrupado[~df_agrupado['chave'].isin(processados)]\n",
    "\n",
    "# # Exibir os locais e datas que faltam processar\n",
    "# print(f\"Total de registros faltantes: {len(faltantes)}\")\n",
    "# print(faltantes[['Local de instalação', 'Ano Mes', 'Latitude', 'Longitude']])\n",
    "\n",
    "# # Você pode agora usar o DataFrame `faltantes` para fazer as requisições restantes à API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Configurar a sessão da API com cache\n",
    "# cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "# openmeteo = Client(session=cache_session)\n",
    "\n",
    "# # Definir o tamanho do lote e o tempo de pausa entre os lotes (em segundos)\n",
    "# lote_tamanho = 50  # Por exemplo, 50 registros por lote\n",
    "# tempo_pausa = 5  # Pausa para respeitar o limite de API (60 segundos)\n",
    "\n",
    "# # Preparar um DataFrame para armazenar os novos resultados\n",
    "# novos_resultados = []\n",
    "\n",
    "# # Iterar sobre os registros faltantes em lotes\n",
    "# for i in range(0, len(faltantes), lote_tamanho):\n",
    "#     lote_faltantes = faltantes.iloc[i:i + lote_tamanho]\n",
    "\n",
    "#     # Fazer requisições para cada registro no lote\n",
    "#     for index, row in lote_faltantes.iterrows():\n",
    "#         ano_mes = str(row['Ano Mes'])\n",
    "#         ano, mes = ano_mes.split(\"-\")\n",
    "#         latitude = row['Latitude']\n",
    "#         longitude = row['Longitude']\n",
    "\n",
    "#         # Definir a data de início e fim do mês\n",
    "#         start_date = f\"{ano}-{mes}-01\"\n",
    "#         end_date = f\"{ano}-{mes}-{pd.Period(start_date).days_in_month}\"\n",
    "\n",
    "#         # Parâmetros para a solicitação da API\n",
    "#         params = {\n",
    "#             \"latitude\": latitude,\n",
    "#             \"longitude\": longitude,\n",
    "#             \"start_date\": start_date,\n",
    "#             \"end_date\": end_date,\n",
    "#             \"daily\": [\n",
    "#                 \"weather_code\", \"temperature_2m_max\", \"temperature_2m_min\", \"temperature_2m_mean\",\n",
    "#                 \"precipitation_sum\", \"rain_sum\", \"precipitation_hours\",\n",
    "#                 \"wind_speed_10m_max\", \"wind_gusts_10m_max\"\n",
    "#             ],\n",
    "#             \"timezone\": \"America/Sao_Paulo\"\n",
    "#         }\n",
    "\n",
    "#         # Solicitar dados à API\n",
    "#         try:\n",
    "#             response = openmeteo.weather_api(\"https://archive-api.open-meteo.com/v1/archive\", params=params)[0]\n",
    "\n",
    "#             # Processar os dados diários\n",
    "#             daily = response.Daily()\n",
    "#             daily_data = {\n",
    "#                 \"date\": pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "#                 \"weather_code\": daily.Variables(0).ValuesAsNumpy(),\n",
    "#                 \"temperature_2m_max\": daily.Variables(1).ValuesAsNumpy(),\n",
    "#                 \"temperature_2m_min\": daily.Variables(2).ValuesAsNumpy(),\n",
    "#                 \"temperature_2m_mean\": daily.Variables(3).ValuesAsNumpy(),\n",
    "#                 \"precipitation_sum\": daily.Variables(4).ValuesAsNumpy(),\n",
    "#                 \"rain_sum\": daily.Variables(5).ValuesAsNumpy(),\n",
    "#                 \"precipitation_hours\": daily.Variables(6).ValuesAsNumpy(),\n",
    "#                 \"wind_speed_10m_max\": daily.Variables(7).ValuesAsNumpy(),\n",
    "#                 \"wind_gusts_10m_max\": daily.Variables(8).ValuesAsNumpy(),\n",
    "#             }\n",
    "\n",
    "#             daily_dataframe = pd.DataFrame(data=daily_data)\n",
    "\n",
    "#             # Calcular as médias das variáveis meteorológicas para o mês\n",
    "#             monthly_averages = daily_dataframe.mean()\n",
    "\n",
    "#             # Adicionar os resultados ao DataFrame final\n",
    "#             novos_resultados.append({\n",
    "#                 \"Ano-Mes\": ano_mes,\n",
    "#                 \"Local de instalação\": row['Local de instalação'],\n",
    "#                 \"Latitude\": latitude,\n",
    "#                 \"Longitude\": longitude,\n",
    "#                 \"HH total\": row['HH total'],\n",
    "#                 \"Temp_Max\": monthly_averages['temperature_2m_max'],\n",
    "#                 \"Temp_Min\": monthly_averages['temperature_2m_min'],\n",
    "#                 \"Temp_Mean\": monthly_averages['temperature_2m_mean'],\n",
    "#                 \"Precipitation_Sum\": monthly_averages['precipitation_sum'],\n",
    "#                 \"Rain_Sum\": monthly_averages['rain_sum'],\n",
    "#                 \"Precipitation_Hours\": monthly_averages['precipitation_hours'],\n",
    "#                 \"Wind_Speed_Max\": monthly_averages['wind_speed_10m_max'],\n",
    "#                 \"Wind_Gusts_Max\": monthly_averages['wind_gusts_10m_max']\n",
    "#             })\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Erro ao solicitar dados da API para {row['Local de instalação']} em {ano_mes}: {e}\")\n",
    "\n",
    "#     # Pausar entre os lotes para não exceder o limite de requisições\n",
    "#     if (i + lote_tamanho) < len(faltantes):  # Apenas pausar se houver mais registros a serem processados\n",
    "#         print(f\"Pausando para evitar limite da API...\")\n",
    "#         time.sleep(tempo_pausa)\n",
    "#         print(f\"Voltando\")\n",
    "\n",
    "# # Converter a lista de resultados para um DataFrame\n",
    "# df_novos_resultados = pd.DataFrame(novos_resultados)\n",
    "\n",
    "# # Salvar os novos resultados em um CSV (opcional)\n",
    "# df_novos_resultados.to_csv(path_iw + \"novos_resultados_meteorologicos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combinar os dados novos com os resultados antigos\n",
    "# df_todos_resultados = pd.concat([df_resultados, df_novos_resultados])\n",
    "\n",
    "# # Salvar todos os resultados combinados (opcional)\n",
    "# df_todos_resultados.to_csv(path_iw + \"resultados_meteorologicos_completos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando Dados Meteorologicos Ja Coletados pela API da OpenMeteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le resultados_meteorologicos_completos\n",
    "\n",
    "path_ipt = \"data/input/\"\n",
    "\n",
    "path_ipt = ajuste_path(path_ipt)\n",
    "\n",
    "df_resultados_completos = pd.read_csv(\n",
    "    path_ipt + \"resultados_meteorologicos_completos.csv\")\n",
    "\n",
    "df_resultados_completos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que df_resultados_completos já esteja carregado\n",
    "df_resultados_completos = df_resultados_completos.drop(columns=['chave'])\n",
    "\n",
    "# Renomear a coluna 'Ano-Mes' para 'Ano Mes'\n",
    "df_resultados_completos = df_resultados_completos.rename(\n",
    "    columns={'Ano-Mes': 'Ano Mes'})\n",
    "\n",
    "# Verifique o DataFrame para garantir que a coluna foi renomeada\n",
    "print(df_resultados_completos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXPORTANDO PLANILHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar o tipo de dados da coluna 'Ano Mes' em df_resultados_completos\n",
    "print(df_resultados_completos['Ano Mes'].dtype)\n",
    "\n",
    "# Verificar o tipo de dados da coluna 'Ano Mes' em df_agrupado\n",
    "print(df_agrupado['Ano Mes'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter a coluna 'Ano Mes' para string em ambos os DataFrames\n",
    "df_resultados_completos['Ano Mes'] = df_resultados_completos['Ano Mes'].astype(\n",
    "    str)\n",
    "df_agrupado['Ano Mes'] = df_agrupado['Ano Mes'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que df_resultados_completos e df_agrupado já estejam carregados\n",
    "\n",
    "# Realizar a junção (merge) com base na coluna-chave\n",
    "df_merged = df_resultados_completos.merge(df_agrupado, on=[\n",
    "                                          'Ano Mes', 'Local de instalação', 'Latitude', 'Longitude'], how='right')\n",
    "\n",
    "# Verifique o resultado da concatenação\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropar a coluna 'HH total_x'\n",
    "df_merged = df_merged.drop(columns=['HH total_x'])\n",
    "\n",
    "# Renomear a coluna 'HH total_y' para 'HH total'\n",
    "df_merged = df_merged.rename(columns={'HH total_y': 'HH total'})\n",
    "\n",
    "# Verifique o resultado\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado = df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXPORTANDO PLANILHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agrupado.to_csv(path_iw + \"os_treinamento.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
