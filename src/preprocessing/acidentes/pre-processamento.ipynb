{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook de pré-processamento da planilha BD Acidentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports e dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz, process\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resolve_path import ajuste_path, read_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se nao tiver a pasta dados, criar a pasta dados e colocar o arquivo bd acidentes mais recente dentro dela\n",
    "path = \"data/\"\n",
    "\n",
    "pathIn = path + \"input/\"\n",
    "pathUtil = path + \"util/\"\n",
    "pathUtil = ajuste_path(pathUtil)\n",
    "\n",
    "arquivo = \"BD_Acidentes_13_08.csv\"\n",
    "\n",
    "df = read_input(pathIn + arquivo)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrindo dataframe das coordenadas e seus locais de instalação correspondentes\n",
    "dataFrameInstalacao = pd.read_csv(\n",
    "    pathUtil + \"local_coordenada.csv\", sep=\";\")\n",
    "dataFrameInstalacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição de Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printa os tipos de dados presentes na coluna\n",
    "\n",
    "\n",
    "def checa_tipos(coluna):\n",
    "    count_string = 0\n",
    "    count_float = 0\n",
    "    count_int = 0\n",
    "    count_na = 0\n",
    "    count_outros = 0\n",
    "    for i in coluna:\n",
    "        if pd.isna(i):\n",
    "            count_na += 1\n",
    "        elif type(i) == str:\n",
    "            count_string += 1\n",
    "        elif type(i) == float:\n",
    "            count_float += 1\n",
    "        elif type(i) == int:\n",
    "            count_int += 1\n",
    "        else:\n",
    "            count_outros += 1\n",
    "    print(\"NAs: \", count_na)\n",
    "    print(\"Strs: \", count_string)\n",
    "    print(\"Floats: \", count_float)\n",
    "    print(\"Ints: \", count_int)\n",
    "    print(\"Outros: \", count_outros)\n",
    "\n",
    "\n",
    "# Exibe informações sobre a coluna\n",
    "def exibe_coluna(nome_col):\n",
    "    print(checa_tipos(df[nome_col]))\n",
    "    print()\n",
    "    qt = df[nome_col].nunique()\n",
    "    print(\"quantidade de diferentes entradas:\", qt)\n",
    "    print()\n",
    "    if qt <= 10:\n",
    "        print(\"Os diferentes valores nas colunas:\", df[nome_col].unique())\n",
    "        print()\n",
    "    print(df[nome_col].value_counts(dropna=False))\n",
    "    print()\n",
    "    return\n",
    "\n",
    "\n",
    "# Converte datas do excel para datetime\n",
    "def converte_data_excel(value):\n",
    "    excel_data_inicio = datetime.datetime(1899, 12, 30)\n",
    "    if isinstance(value, int):\n",
    "        return excel_data_inicio + datetime.timedelta(days=value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "# Conversão para Minúsculas e Remoção de Acentos\n",
    "def formata_string(string):\n",
    "    if isinstance(string, str):\n",
    "        string = string.lower().strip()\n",
    "        string = unidecode(string)\n",
    "        if string == \"-\":\n",
    "            return np.nan\n",
    "        return string\n",
    "    return string\n",
    "\n",
    "\n",
    "# Remove os espaços das strings de uma coluna\n",
    "def remove_espaços(string):\n",
    "    r = string\n",
    "    if type(string) == str:\n",
    "        r = string.replace(\" \", \"\")\n",
    "    return r\n",
    "\n",
    "\n",
    "# Remove coluna\n",
    "def remove_coluna(df, coluna):\n",
    "    if coluna in df.columns:\n",
    "        df.drop(coluna, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Calcula distancias entre dois pontos de uma esfera a partir de suas latitudes e longitudes\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    import math\n",
    "\n",
    "    R = 6371\n",
    "\n",
    "    d_lat = math.radians(lat2 - lat1)\n",
    "    d_lon = math.radians(lon2 - lon1)\n",
    "    a = math.sin(d_lat / 2) * math.sin(d_lat / 2) + math.cos(\n",
    "        math.radians(lat1)\n",
    "    ) * math.cos(math.radians(lat2)) * math.sin(d_lon / 2) * math.sin(d_lon / 2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = R * c\n",
    "    return d\n",
    "\n",
    "\n",
    "# Define o Local de Instalação daquele acidente com base em suas coordenadas\n",
    "def calcula_local_instalacao_acidente(raio, dfAcidentes, dfInstalacaoCoordenadas):\n",
    "    lat_long = dfAcidentes[[\"Latitude\", \"Longitude\"]].dropna()\n",
    "    lat_long[\"Longitude\"] = lat_long[\n",
    "        \"Longitude\"\n",
    "    ].apply(  # coordenada digitada errada (numero muito grande)\n",
    "        lambda x: x / 100000 if x < -100 else x\n",
    "    )\n",
    "    lat_long[\"Longitude\"] = lat_long[\n",
    "        \"Longitude\"\n",
    "    ].apply(  # sinal das coordenadas trocado\n",
    "        lambda x: x * (-1) if x > 0 else x\n",
    "    )\n",
    "\n",
    "    lat_long[\"Longitude\"] = lat_long[\n",
    "        \"Longitude\"\n",
    "    ].apply(  # virgulas das coordenadas digitadas errado\n",
    "        lambda x: x * 10 if x > -10 else x\n",
    "    )\n",
    "    # pontos na antartica desconsiderados\n",
    "    lat_long = lat_long[lat_long[\"Latitude\"] > -40]\n",
    "\n",
    "    for index, row in lat_long.iterrows():\n",
    "        menor_distancia = raio\n",
    "        idx_menor_distancia = -1\n",
    "        tolerancia = 0.1\n",
    "        df_locais_proximos = dfInstalacaoCoordenadas[(dfInstalacaoCoordenadas['Latitude'] < row['Latitude'] + tolerancia) & (dfInstalacaoCoordenadas['Latitude'] > row['Latitude'] - tolerancia) & (\n",
    "            dfInstalacaoCoordenadas['Longitude'] < row['Longitude'] + tolerancia) & (dfInstalacaoCoordenadas['Longitude'] > row['Longitude'] - tolerancia)]\n",
    "        for index2, row2 in df_locais_proximos.iterrows():\n",
    "            distance = haversine(\n",
    "                row2[\"Latitude\"], row2[\"Longitude\"], row[\"Latitude\"], row[\"Longitude\"]\n",
    "            )\n",
    "            if distance < menor_distancia:\n",
    "                menor_distancia = distance\n",
    "                idx_menor_distancia = index2\n",
    "        if idx_menor_distancia == -1:\n",
    "            continue\n",
    "        dfAcidentes.loc[index, \"Local de instalação\"] = dfInstalacaoCoordenadas.loc[\n",
    "            idx_menor_distancia, \"Local de instalação\"\n",
    "        ]\n",
    "        # colocar coluna distancia para a subestação mais proxima\n",
    "        dfAcidentes.loc[index, \"Distancia\"] = menor_distancia\n",
    "\n",
    "    # print(\"Quantidade de Acidentes:\", qtdAcidentes)\n",
    "    return dfAcidentes\n",
    "\n",
    "\n",
    "# Função para encontrar valores similares\n",
    "def achar_valores_similares(column, threshold=90):\n",
    "    unique_values = column.unique()\n",
    "    similar_pairs = []\n",
    "\n",
    "    for value in unique_values:\n",
    "        matches = process.extract(\n",
    "            value, unique_values, limit=len(unique_values))\n",
    "        for match in matches:\n",
    "            if match[1] >= threshold and match[0] != value:\n",
    "                similar_pairs.append((value, match[0], match[1]))\n",
    "\n",
    "    return similar_pairs\n",
    "\n",
    "\n",
    "def processa_coordenada(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.replace(\",\", \".\")  # Substitui vírgula por ponto\n",
    "        value = value.replace(\"°\", \"\")  # Remove \"°\"\n",
    "        return float(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "# Inverte uma lista de dicionários onde os valores são listas de chaves a serem substituídas pelo valor correspondente.\n",
    "def inverte_lista_de_dict(d):\n",
    "    subs = {}\n",
    "    for dic in d:\n",
    "        if dic == {}:\n",
    "            continue\n",
    "        for valor, a_substituir in dic.items():\n",
    "\n",
    "            for chave in a_substituir:\n",
    "                subs[chave] = valor\n",
    "    return subs\n",
    "\n",
    "\n",
    "# Verifica se foi definida algum local de instalação fora da Eletrosul\n",
    "def checar_acidente_fora_eletrosul(df):\n",
    "    count_nao_vazios = 0\n",
    "    # Filtrar o DataFrame com base na condição\n",
    "    df_filtrada = df[df[\"Empresa\"] != \"cgt eletrosul\"]\n",
    "    df_filtrada = df[df[\"Empresa\"] != \"cgt eletrosul\"]\n",
    "\n",
    "    # Verificar se há valores não vazios na coluna_verificar\n",
    "    valores_nao_vazios = df_filtrada[\"Local de instalação\"].apply(\n",
    "        lambda x: not pd.isnull(x) and (isinstance(x, str) and x.strip() != \"\")\n",
    "    )\n",
    "\n",
    "    # Retornar True se houver algum valor não vazio, caso contrário, False\n",
    "    if valores_nao_vazios.any():\n",
    "        count_nao_vazios += 1\n",
    "    return count_nao_vazios\n",
    "\n",
    "\n",
    "# Verificando se pode colocar | para separar o csv sem perda de valores\n",
    "def possui_pipe(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].apply(lambda x: \"|\" in str(x)).any():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Codigo\n",
    "\n",
    "Considerações: Foi removida esta coluna; todos os valores são 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_coluna(df, \"Codigo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Empregado\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Empregado\"] = df[\"Empregado\"].apply(formata_string)\n",
    "df[\"Empregado\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Classificação\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Classificação\"] = df[\"Classificação\"].apply(formata_string)\n",
    "df[\"Classificação\"] = df[\"Classificação\"].apply(formata_string)\n",
    "df[\"Classificação\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Nexo Causal\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula após transformar tudo em string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Nexo causal\"] = df[\"Nexo causal\"].astype(dtype=\"string\")\n",
    "\n",
    "df[\"Nexo causal\"] = df[\"Nexo causal\"].apply(formata_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Empresa\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Empresa\"] = df[\"Empresa\"].apply(formata_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Fornecedor\n",
    "\n",
    "Considerações: foi feita uma análise de alguns nomes parecidos para que se pudesse reduzir a quantidade de entradas únicas nesta coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NA e strings vazias\n",
    "df = df.dropna(subset=[\"Fornecedor\"])\n",
    "\n",
    "# Converte a coluna \"Fornecedor\" para o tipo string\n",
    "df.loc[:, \"Fornecedor\"] = df[\"Fornecedor\"].astype(dtype=\"string\")\n",
    "\n",
    "# Aplica a função formata_string na coluna \"Fornecedor\"\n",
    "df.loc[:, \"Fornecedor\"] = df[\"Fornecedor\"].apply(formata_string)\n",
    "df.loc[:, \"Fornecedor\"] = df[\"Fornecedor\"].apply(formata_string)\n",
    "\n",
    "df.loc[df[\"Fornecedor\"] == 'n.a.', \"Fornecedor\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_forn = df[(df[\"Ano\"] == 2022) & (df[\"Mês\"] >= 11)]\n",
    "df2023e2024_forn = df[(df[\"Ano\"] > 2022)]\n",
    "\n",
    "df_ultimos_18meses_forn = pd.concat(\n",
    "    [df2022_forn, df2023e2024_forn], ignore_index=True)\n",
    "\n",
    "df2022_antes_forn = df[(df[\"Ano\"] == 2022) & (df[\"Mês\"] < 11)]\n",
    "df2020e2021_antes_forn = df[(df[\"Ano\"] <= 2021)]\n",
    "\n",
    "# O DataFrame \"df_antes_ultimos_18meses\" contém os registros relativos ao período anterior dos últimos 18 meses\n",
    "df_antes_ultimos_18meses_forn = pd.concat(\n",
    "    [df2020e2021_antes_forn, df2022_antes_forn], ignore_index=True\n",
    ")\n",
    "\n",
    "# Últimos 18 meses\n",
    "lista_nomes_unicos_ultimos18meses_forn = df_ultimos_18meses_forn[\"Fornecedor\"].unique(\n",
    ")\n",
    "\n",
    "\n",
    "# Meses anteriores\n",
    "lista_nomes_unicos_antes_ultimos18meses_forn = df_antes_ultimos_18meses_forn[\n",
    "    \"Fornecedor\"\n",
    "].unique()\n",
    "\n",
    "# Criação da lista que contém os dicionários\n",
    "lista_nomes_empregos_forn = list()\n",
    "\n",
    "for nome_emprego in lista_nomes_unicos_ultimos18meses_forn:\n",
    "    # Condição que pula o registro, caso ele seja um Nan\n",
    "    if (\n",
    "        type(nome_emprego) == pd._libs.missing.NAType\n",
    "    ):  # pd._libs.missing.NAType é um tipo de Nan do pandas\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        # Criação da lista que vai conter os nomes a serem substituidos\n",
    "        lista_nomes = list()\n",
    "\n",
    "        # Adicionar dicionário à lista de dicionários\n",
    "        # O índice é o valor a substituir que vem de lista_nomes_unicos_ultimos18meses\n",
    "        # lista_nomes é lista vazia que irá conter os nomes a substituir que serão adicionados a lista no loop abaixo\n",
    "        lista_nomes_empregos_forn.append({nome_emprego: lista_nomes})\n",
    "\n",
    "        for index in range(len(lista_nomes_unicos_antes_ultimos18meses_forn)):\n",
    "            if (\n",
    "                fuzz.token_sort_ratio(\n",
    "                    nome_emprego, lista_nomes_unicos_antes_ultimos18meses_forn[index]\n",
    "                )\n",
    "                > 80\n",
    "            ):\n",
    "                # print(nome_emprego + \" - \" + lista_nomes_unicos_antes_ultimos18meses[index])\n",
    "                lista_nomes.append(\n",
    "                    lista_nomes_unicos_antes_ultimos18meses_forn[index])\n",
    "\n",
    "lista_nomes_empregos_forn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Através de uma análise visual da lista \"lista_nomes_empregos_forn\", percebe-se que as empresas estão, em sua maior parte, com nomes corretos.\n",
    "\n",
    "Abaixo são feitas as substituições para nomes que apresentaram erros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fornecedor\"].replace(\n",
    "    to_replace=\"vividense linhas de transmissao ltda.\",\n",
    "    value=\"vividence linhas de transmissao ltda\",\n",
    "    inplace=True,\n",
    ")\n",
    "df[\"Fornecedor\"].replace(\n",
    "    to_replace=\"ts infraestrutura e engenharia\",\n",
    "    value=\"ts infraestrutura e engenharia s.a\",\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Nesse caso, acho que a pessoa quis escrever \"eireli\" e não \"eirelli\"\n",
    "df[\"Fornecedor\"].replace(\n",
    "    to_replace=\"rp manutencao industrial eirelli\",\n",
    "    value=\"rp manutencao industrial\",\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Nº do Contrato\n",
    "\n",
    "Considerações: não foi feita alteração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Segmento\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Segmento\"] = df[\"Segmento\"].astype(dtype=\"string\")\n",
    "\n",
    "df[\"Segmento\"] = df[\"Segmento\"].apply(formata_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Função\n",
    "\n",
    "Considerações: foi feita uma análise de alguns nomes parecidos para que se pudesse reduzir a quantidade de entradas únicas nesta coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Função\"] = df[\"Função\"].astype(dtype=\"string\")\n",
    "\n",
    "df[\"Função\"] = df[\"Função\"].apply(formata_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna \"Função\" do dataset original continha multiplos nomes para denotar o mesmo cargo (ex.: as strings \"Tec. Elet.\", \"Tec Elet\" e \"Tecnico eletr.\" usadas para representar \"Tecnico eletricista\").\n",
    "A fim de padronizar a nomenclatura utilizada para nomear cada função (emprego) dos trabalhadores acidentados, optou-se por utilizar as entradas únicas de string da coluna \"Função\" dos últimos 18 meses e procurar strings coincidentes na parcela restante do dataset. Tal escolha foi motivada pela informação passada pelo Clebsow na primeira reunião feita com ele, onde foi citado que os dados dos últimos 18 meses eram mais confiáveis.\n",
    "\n",
    "Para realizar a padronização, escolheu-se utilizar a biblioteca **thefuzz** (https://github.com/seatgeek/thefuzz), a qual utiliza a distância de Levenshtein para realizar operações de string matching. \n",
    "\n",
    "A função utilizada para realizar a padronização não foi escolhida usando uma justificativa racional. A função \"token_sort_ratio\" foi escolhida por ter retornado os resultados mais coerentes (para 80% de similariedade entre as strings) entre as funções testadas da biblioteca thefuzz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção do dataset dos últimos 18 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022 = df[(df[\"Ano\"] == 2022) & (df[\"Mês\"] >= 11)]\n",
    "df2023e2024 = df[(df[\"Ano\"] > 2022)]\n",
    "\n",
    "# O DataFrame \"df_ultimos_18meses\" contém os registros relativos aos últimos 18 meses\n",
    "df_ultimos_18meses = pd.concat([df2022, df2023e2024], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção do dataset do período anterior aos últimos 18 meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_antes = df[(df[\"Ano\"] == 2022) & (df[\"Mês\"] < 11)]\n",
    "df2020e2021_antes = df[(df[\"Ano\"] <= 2021)]\n",
    "\n",
    "# O DataFrame \"df_antes_ultimos_18meses\" contém os registros relativos ao período anterior dos últimos 18 meses\n",
    "df_antes_ultimos_18meses = pd.concat(\n",
    "    [df2020e2021_antes, df2022_antes], ignore_index=True\n",
    ")\n",
    "\n",
    "df_antes_ultimos_18meses[\"Ano\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listas com nomes de empregos dos últimos 18 meses e dos meses anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Últimos 18 meses\n",
    "lista_nomes_unicos_ultimos18meses = df_ultimos_18meses[\"Função\"].unique()\n",
    "\n",
    "\n",
    "# Meses anteriores\n",
    "lista_nomes_unicos_antes_ultimos18meses = df_antes_ultimos_18meses[\"Função\"].unique(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de nomes parecidos\n",
    "\n",
    "As linhas abaixo realizam o processo de string matching. A lista \"lista_nomes_empregos\" para conter um conjunto de dicionários que conterão a string que irá substituir strings parecidas (a chave) e uma lista de strings a ser substituidas (o valor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação da lista que contém os dicionários\n",
    "lista_nomes_empregos = list()\n",
    "\n",
    "for nome_emprego in lista_nomes_unicos_ultimos18meses:\n",
    "    # Condição que pula o registro, caso ele seja um Nan\n",
    "    if (\n",
    "        type(nome_emprego) == pd._libs.missing.NAType\n",
    "    ):  # pd._libs.missing.NAType é um tipo de Nan do pandas\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        # Criação da lista que vai conter os nomes a serem substituidos\n",
    "        lista_nomes = list()\n",
    "\n",
    "        # Adicionar dicionário à lista de dicionários\n",
    "        # O índice é o valor a substituir que vem de lista_nomes_unicos_ultimos18meses\n",
    "        # lista_nomes é lista vazia que irá conter os nomes a substituir que serão adicionados a lista no loop abaixo\n",
    "        lista_nomes_empregos.append({nome_emprego: lista_nomes})\n",
    "\n",
    "        for index in range(len(lista_nomes_unicos_antes_ultimos18meses)):\n",
    "            if (\n",
    "                fuzz.token_sort_ratio(\n",
    "                    nome_emprego, lista_nomes_unicos_antes_ultimos18meses[index]\n",
    "                )\n",
    "                > 80\n",
    "            ):\n",
    "                # print(nome_emprego + \" - \" + lista_nomes_unicos_antes_ultimos18meses[index])\n",
    "                lista_nomes.append(\n",
    "                    lista_nomes_unicos_antes_ultimos18meses[index])\n",
    "\n",
    "\n",
    "len(lista_nomes_empregos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O procedimento de string matching acabou retornando algumas relações que considerei erradas. Portanto, abaixo criei uma lista (\"lista_indices errados\") com as chaves dos dicionários contendo listas de strings que não eram parecidas com a string do seu respectivo dicionário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_indices_errados = [\n",
    "    \"tec eletricista\",\n",
    "    \"montador\",\n",
    "    \"tec. manutencao mecanica usina\",\n",
    "    \"as. administrativo\",\n",
    "    \"tec. eletricista\",\n",
    "    \"tecnico manutencao de equipamentos\",\n",
    "    \"eletricista\",\n",
    "    \"eletricista de lt\",\n",
    "    \"servicos gerais\",\n",
    "    \"tecnico manutencao eletronica\",\n",
    "    \"eletricista manutencao\",\n",
    "    \"auxiliar tecnico de manutencao\",\n",
    "    \"montador ii\",\n",
    "    \"operador de trator\",\n",
    "    \"operador de se\",\n",
    "    \"operador de ute\",\n",
    "    \"tecnico de manutencao eletromecanica\",\n",
    "    \"tecnico de manutencao\",\n",
    "    \"eletricista de manutencao\",\n",
    "    \"eletricista de linhas\",\n",
    "    \"tecnico em manutencao eletroeletronica\",\n",
    "    \"tecnico em eletroeletronica\",\n",
    "    \"auxiliar de manutencao\",\n",
    "    \"eletricista de linha de transmissao\",\n",
    "    \"as administrativo\",\n",
    "    \"montador eletrico\",\n",
    "    \"mecanico de maquinas pesadas\",\n",
    "    \"auxiliar tecnico\",\n",
    "    \"apoio tecnico/administrativo\",\n",
    "    \"auxiliar de remocao\",\n",
    "    \"apoio tecnico/administrativo\",\n",
    "    \"eletricista manutencao\",\n",
    "    \"tec eletricista lt\",\n",
    "    \"tecnico eletricista\",\n",
    "    \"servento de obras\",\n",
    "    \"operador de subestacao\",\n",
    "    \"montador i\",\n",
    "    \"contadora\",\n",
    "    \"ajudante de servicos gerais\",\n",
    "]\n",
    "\n",
    "# As linhas abaixo tornam lista_nomes_empregos formatado corretamente para ser passado para a função .replace de pandas\n",
    "for dicts in lista_nomes_empregos:\n",
    "    for key in lista_indices_errados:\n",
    "        if key in dicts:\n",
    "            dicts.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção dos dicionários com listas vazias e apropriação do dicionário de substituições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_nomes_empregos_limpos = [\n",
    "    d\n",
    "    for d in lista_nomes_empregos\n",
    "    if not any(isinstance(v, list) and not v for v in d.values())\n",
    "]\n",
    "\n",
    "lista_nomes_empregos_limpos = inverte_lista_de_dict(\n",
    "    lista_nomes_empregos_limpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituição dos nomes parecidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Função\"].replace(lista_nomes_empregos_limpos, inplace=True)\n",
    "df[\"Função\"].replace(to_replace=\"mototrista\", value=\"motorista\", inplace=True)\n",
    "\n",
    "# Substituição de nomes usados para denominar Nan para um valor Nan do pandas\n",
    "df[\"Função\"].replace(\n",
    "    to_replace=\"n.a.\", value=pd._libs.missing.NAType, inplace=True)\n",
    "df[\"Função\"].replace(\n",
    "    to_replace=\"-\", value=pd._libs.missing.NAType, inplace=True)\n",
    "df[\"Função\"].replace(\n",
    "    to_replace=\"--\", value=pd._libs.missing.NAType, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lista_nomes_empregos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Sexo\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sexo\"] = df[\"Sexo\"].astype(dtype=\"string\")\n",
    "\n",
    "df[\"Sexo\"] = df[\"Sexo\"].apply(formata_string)\n",
    "df[\"Sexo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Idade\n",
    "\n",
    "Considerações: foi substituida a entrada diferente do padrão por algo que o obedeça, permitindo uma troca do tipo da coluna.\n",
    "Foi substituido o cluster >60 para 61, para que todos os valores da coluna fossem numericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Idade\"].dtypes)\n",
    "\n",
    "df[\"Idade\"].replace(to_replace=\"> 60\", value=61, inplace=True)\n",
    "\n",
    "df[\"Idade\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Tempo de Empresa\n",
    "\n",
    "Considerações: foi feito um label encoding para a informação poder ser traduzida de maneira mais computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Tempo de Empresa\"\n",
    "\n",
    "exibe_coluna(col)\n",
    "\n",
    "subs = {\n",
    "    \"Até 6 meses\": 0,\n",
    "    \"6 meses a 1 ano\": 1,\n",
    "    \"1 a 3 anos\": 2,\n",
    "    \"3 a 6 anos\": 3,\n",
    "    \"6 a 10 anos\": 4,\n",
    "    \"Acima de 10 anos\": 5,\n",
    "    \"10 a 15 anos\": 5,\n",
    "    \"15 a 20 anos\": 5,\n",
    "    \"20 a 25 anos\": 5,\n",
    "    \"30 a 35 anos\": 5,\n",
    "}\n",
    "\n",
    "df[col].replace(subs, inplace=True)\n",
    "\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Dia da Semana\n",
    "\n",
    "Considerações: foi padronizado a maneira de escrita do dia da semana, além da formatação padrão sem acentos e tudo minúsculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Dia da Semana\"\n",
    "\n",
    "exibe_coluna(col)\n",
    "\n",
    "df[col] = df[col].apply(formata_string)\n",
    "df[col] = df[col].apply(remove_espaços)\n",
    "\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Dia\n",
    "\n",
    "Considerações: não foram necessárias alterações; foi utilizada para criar a coluna **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Dia\"\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Mês\n",
    "\n",
    "Considerações: não foram necessárias alterações; foi utilizada para criar a coluna **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Mês\"\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Ano\n",
    "\n",
    "Considerações: não são necessárias alterações.; foi utilizada para criar a coluna **Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Ano\"\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Hora\n",
    "\n",
    "Considerações: Foi necessário substituir os horários para ser lido de maneira uniforme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**específico:**\n",
    "    Foram trocados os horários de início e fim apenas pelo horário de início, sem minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Hora\"\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = df[\"Hora\"].unique()\n",
    "\n",
    "for hora in valores:\n",
    "    try:\n",
    "        subs[hora] = hora[:2]\n",
    "    except:\n",
    "        # subs['Hora'][np.nan] = 'nao informado'\n",
    "        pass\n",
    "\n",
    "print(json.dumps(subs, indent=4))\n",
    "\n",
    "df[\"Hora\"].replace(subs, inplace=True)\n",
    "\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando a coluna **data** \n",
    "Considerações: Para ter mais fácil manipulação  dos dados, é adicionada a coluna 'Data' com o tipo datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Dia\"].unique())\n",
    "print(df[\"Mês\"].unique())\n",
    "print(df[\"Ano\"].unique())\n",
    "\n",
    "df[\"year\"] = df[\"Ano\"]\n",
    "df[\"month\"] = df[\"Mês\"]\n",
    "df[\"day\"] = df[\"Dia\"]\n",
    "df[\"hour\"] = df[\"Hora\"].fillna(\n",
    "    12\n",
    "    # só tem uma linha com NaN, decidi preencher com um valor para não perder as outras informações.\n",
    ")\n",
    "df[\"hour\"] = df[\"hour\"].astype(int)\n",
    "df[\"Data\"] = pd.to_datetime(df[[\"year\", \"month\", \"day\", \"hour\"]])\n",
    "\n",
    "remove_coluna(df, \"year\")\n",
    "remove_coluna(df, \"month\")\n",
    "remove_coluna(df, \"day\")\n",
    "remove_coluna(df, \"hour\")\n",
    "\n",
    "exibe_coluna(\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Descrição\n",
    "\n",
    "Considerações: foi retirado acentos, maiúsculas, cedilhas e espaço."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Descrição\"\n",
    "df[\"Descrição\"] = df[\"Descrição\"].astype(dtype=\"string\")\n",
    "print(df[\"Descrição\"].shape)\n",
    "df[\"Descrição\"].isna().reset_index().query(\"Descrição==True\")[\n",
    "    \"index\"\n",
    "]  # acha o nan na tabela.\n",
    "\n",
    "# Padronizando a coluna\n",
    "df[\"Descrição\"] = df[\"Descrição\"].apply(formata_string)\n",
    "df[\"Descrição\"] = df[\"Descrição\"].apply(formata_string)\n",
    "\n",
    "# Troca todos os ';' por ','\n",
    "df[\"Descrição\"].replace(\";\", \",\", inplace=True)\n",
    "df[\"Descrição\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Local\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Local\"\n",
    "exibe_coluna(col)\n",
    "\n",
    "df[\"Local\"] = df[\"Local\"].apply(formata_string)\n",
    "print(df[\"Local\"].unique())\n",
    "df[\"Local\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Tipo de Trabalho\n",
    "\n",
    "Considerações: Foi ajustada uma única entrada errônea como NaN; fora esta não foram feitas alterações e foi retirada acentos, espaços e letras maiúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Tipo de Trabalho\"\n",
    "df[col] = df[col].astype(dtype=\"string\")\n",
    "\n",
    "# exibe_coluna(col)\n",
    "\n",
    "df[col].replace(to_replace=\"Sem Lesões\", value=np.nan, inplace=True)\n",
    "df[col] = df[col].apply(formata_string)\n",
    "df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Município\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Município\"\n",
    "df[col].shape\n",
    "# df[\"Município\"] = df[\"Município\"].astype(dtype=\"string\")\n",
    "\n",
    "# df[col] = df[col].apply(formata_string)\n",
    "\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Estado\n",
    "considerações: não são necessárias alterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Estado\"\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Instalação \n",
    "Considerações: Remoção de acentos e formatação para letra minúscula. Também foi feito análise de valores únicos para conferir se há erros de digitação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Instalação\"\n",
    "exibe_coluna(col)\n",
    "\n",
    "df[col] = df[col].apply(formata_string)\n",
    "\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que todos os valores na coluna são strings\n",
    "df[\"Instalação\"] = df[\"Instalação\"].astype(str).fillna(\"\")\n",
    "\n",
    "# Encontrar valores similares na coluna 'Instalação'\n",
    "similar_values = achar_valores_similares(df[\"Instalação\"])\n",
    "tam = len(similar_values)\n",
    "i = 0\n",
    "while i < tam:\n",
    "    if similar_values[i][2] > 92:\n",
    "        print(similar_values[i])\n",
    "        print(\"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Instalação\"\n",
    "df[col] = df[col].replace(\"se araraqura\", \"se araraquara\", regex=True)\n",
    "df[col] = df[col].replace(\"empresa - sede\", \"sede empresa\", regex=True)\n",
    "df[col] = df[col].replace(\"usina de sobradinho\",\n",
    "                          \"usina sobradinho\", regex=True)\n",
    "df[col] = df[col].replace(\"usina de boa esperanca\",\n",
    "                          \"usina boa esperanca\", regex=True)\n",
    "df[col] = df[col].replace(\"\", \"\", regex=True)\n",
    "# antigo: 287\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colunas Latitude e Longitude\n",
    "considerações: remove \"°\" e troca ',' por '.' nas coordenadas e transforma todos os valores para float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Latitude\"\n",
    "exibe_coluna(col)\n",
    "\n",
    "\n",
    "col = \"Longitude\"\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"°\" das coordenadas e garante que todas são float\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Aplicar a função às colunas 'Latitude' e 'Longitude'\n",
    "df[\"Latitude\"] = df[\"Latitude\"].apply(processa_coordenada)\n",
    "df[\"Longitude\"] = df[\"Longitude\"].apply(processa_coordenada)\n",
    "df[\"Latitude\"] = df[\"Latitude\"].apply(processa_coordenada)\n",
    "df[\"Longitude\"] = df[\"Longitude\"].apply(processa_coordenada)\n",
    "\n",
    "# Exibir as primeiras 10 linhas\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Vice-presidência\n",
    "considerações: não foram feitas alterações. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Vice-presidência\"\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Diretoria \n",
    "\n",
    "considerações: Foi ajustada apenas uma linha errônea, que estava com capitalização errônea. Também foi padronizado para letra minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Diretoria\"\n",
    "# exibe_coluna(col)\n",
    "df[col] = df[col].astype(str)\n",
    "\n",
    "subs = {\n",
    "    \"Engenharia\": \"engenharia\",\n",
    "    \"Operações\": \"operações\",\n",
    "    \"Outros\": \"outros\",\n",
    "    \"VSS\": \"vss\",\n",
    "}\n",
    "\n",
    "df[col].replace(subs, inplace=True)\n",
    "\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Gerência Executiva \n",
    "Considerações: Remoção de acentos e formatação para letra minúscula. Também foi feito análise de valores únicos para conferir se há erros de digitação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Gerência Executiva\"\n",
    "exibe_coluna(col)\n",
    "\n",
    "df[col] = df[col].apply(formata_string)\n",
    "\n",
    "exibe_coluna(col)\n",
    "\n",
    "df[col].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que todos os valores na coluna são strings\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].astype(str).fillna(\"\")\n",
    "\n",
    "# Encontrar valores similares na coluna 'Gerência Executiva'\n",
    "similar_values = achar_valores_similares(df[\"Gerência Executiva\"])\n",
    "tam = len(similar_values)\n",
    "i = 0\n",
    "while i < tam:\n",
    "    print(similar_values[i])\n",
    "    print(\"\\n\")\n",
    "    i += 1\n",
    "print(similar_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir usando expressões regulares\n",
    "col = \"Gerência Executiva\"\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"dgp departramento de gestao de pessoas\",\n",
    "    \"departamento de gestao de pessoas\",\n",
    "    regex=True,\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"fr.sdepartamento de produtividade e qualidade da unidade sul\",\n",
    "    \"departamento de produtividade e qualidade da unidade sul\",\n",
    "    regex=True,\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"eeig - implantacao de geracao\", \"eeig - implantacao da geracao\", regex=True\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"superintedencia de gestao de pessoas\",\n",
    "    \"superintendencia de gestao de pessoas\",\n",
    "    regex=True,\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"oog.s - producao de transmissa\", \"oog.s - producao de transmissao\", regex=True\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"superintendencia de producao da geracao hidraulica\\nproducao da geracao hidraulica\",\n",
    "    \"superintendencia de producao da geracao hidraulica\",\n",
    "    regex=True,\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"deg departamento engenharia de geracao\",\n",
    "    \"departamento de engenharia de geracao\",\n",
    "    regex=True,\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"engenharia de geracao\", \"departamento de engenharia de geracao\", regex=True\n",
    ")\n",
    "df[\"Gerência Executiva\"] = df[\"Gerência Executiva\"].replace(\n",
    "    \"dmo departamento de operacao e apoio a  manutencao\",\n",
    "    \"departamento de manutencao e apoio a operacao\",\n",
    "    regex=True,\n",
    ")\n",
    "\n",
    "df[\"Gerência Executiva\"].unique().shape\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Gerência \n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula. Também foi feito análise de valores únicos para conferir se há erros de digitação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Gerência\"\n",
    "exibe_coluna(col)\n",
    "\n",
    "df[col] = df[col].apply(formata_string)\n",
    "\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantir que todos os valores na coluna são strings\n",
    "df[\"Gerência\"] = df[\"Gerência\"].astype(str).fillna(\"\")\n",
    "\n",
    "valores_similares_gerencia = achar_valores_similares(df[\"Gerência\"])\n",
    "tam = len(valores_similares_gerencia)\n",
    "i = 0\n",
    "while i < tam:\n",
    "    if valores_similares_gerencia[i][2] > 95:\n",
    "        print(valores_similares_gerencia[i])\n",
    "        print(\"\\n\")\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"Gerência\"\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento de saude, seguranca e bem-estar no trabalho\",\n",
    "    \"departamento de saude, seguranca e bem-estar do trabalho\",\n",
    "    regex=True,\n",
    ")  # isso nao esta fazendo nada\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento de operacao regional paulo afonso\",\n",
    "    \"departamento de operacao regional de paulo afonso\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento de operacao regional teresina\",\n",
    "    \"departamento de operacao regional de teresina\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento de operacoes regional de fortaleza\",\n",
    "    \"departamento de operacao regional de fortaleza\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento de infraestrurura e servicos gerais do csc\",\n",
    "    \"departamento de infraestrutura e servicos gerais do csc\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento de infraestrutura de servicos gerais csc\",\n",
    "    \"departamento de infraestrutura e servicos gerais do csc\",\n",
    "    regex=True,\n",
    ")  # coloquei essa como certo porque havia outras escritas dessa forma mesmo que com erro de digitacao\n",
    "df[col] = df[col].replace(\"des,o\", \"des.o\", regex=True)\n",
    "df[col] = df[col].replace(\"drt,o\", \"drt.o\", regex=True)\n",
    "df[col] = df[col].replace(\"dit,e\", \"dit.e\", regex=True)\n",
    "df[col] = df[col].replace(\n",
    "    \"ooto.s  regional de manutencao do oeste\",\n",
    "    \"ooto.s regional de manutencao do oeste\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento de operacoes regional de fortaleza\",\n",
    "    \"departamento de operacao regional de fortaleza\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"ooss,c - operacao regional de salvador\",\n",
    "    \"ooss.c - operacao regional de salvador\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"oonf,c - operacao regional de fortaleza\",\n",
    "    \"oonf.c - operacao regional de fortaleza\",\n",
    "    regex=True,\n",
    ")\n",
    "df[col] = df[col].replace(\n",
    "    \"departamento regional de producao e trasmissao do acre e rondonia\",\n",
    "    \"departamento regional de producao e transmissao do acre e rondonia\",\n",
    "    regex=True,\n",
    ")\n",
    "\n",
    "# antiga: 220 entradas diferentes, agora: 208\n",
    "exibe_coluna(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Divisão'\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Divisão\"] = df[\"Divisão\"].apply(formata_string)\n",
    "df[\"Divisão\"] = df[\"Divisão\"].apply(formata_string)\n",
    "\n",
    "print(\"Tipos da coluna Divisão:\")\n",
    "checa_tipos(df[\"Divisão\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colunas 'Data Início do Afastamento' e 'Data Fim do Afastamento'\n",
    "\n",
    "Considerações: Foi feita conversão de datas no formato excel para datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Data Início do Afastamento\"] = df[\"Data Início do Afastamento\"].apply(\n",
    "    converte_data_excel\n",
    ")\n",
    "df[\"Data Início do Afastamento\"] = df[\"Data Início do Afastamento\"].replace(\n",
    "    \" \", np.nan)\n",
    "df[\"Data Fim do Afastamento\"] = df[\"Data Fim do Afastamento\"].apply(\n",
    "    converte_data_excel)\n",
    "\n",
    "print(\"Tipos da coluna Data Início do Afastamento:\")\n",
    "checa_tipos(df[\"Data Início do Afastamento\"])\n",
    "\n",
    "print(\"\\nTipos da coluna Data Fim do Afastamento:\")\n",
    "checa_tipos(df[\"Data Fim do Afastamento\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Dias Perdidos'\n",
    "\n",
    "Considerações: Substituição de hífen por NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui '-' por NaN\n",
    "df[\"Dias Perdidos\"] = df[\"Dias Perdidos\"].replace(\"-\", np.nan)\n",
    "\n",
    "print(\"Tipos da coluna Dias Perdidos:\")\n",
    "checa_tipos(df[\"Dias Perdidos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Dias Debitados'\n",
    "\n",
    "Considerações: Substituição de hífen e string 'Não' por NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui '-' e 'Não' por NaN\n",
    "df[\"Dias Debitados\"] = df[\"Dias Debitados\"].replace(\"-\", np.nan)\n",
    "df[\"Dias Debitados\"] = df[\"Dias Debitados\"].replace(\"Não\", np.nan)\n",
    "\n",
    "print(\"Tipos da coluna Dias Debitados:\")\n",
    "checa_tipos(df[\"Dias Debitados\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Reabilitado'\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Reabilitado\"] = df[\"Reabilitado\"].apply(formata_string)\n",
    "df[\"Reabilitado\"] = df[\"Reabilitado\"].apply(formata_string)\n",
    "\n",
    "print(\"Tipos da coluna Reabilitado:\")\n",
    "checa_tipos(df[\"Reabilitado\"])\n",
    "exibe_coluna(\"Reabilitado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Dias Perdidos Corrigidos'\n",
    "\n",
    "Considerações: Substituição de hífens por NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui '-' por NaN\n",
    "df[\"Dias Perdidos Corrigidos\"] = df[\"Dias Perdidos Corrigidos\"].replace(\n",
    "    \"-\", np.nan)\n",
    "\n",
    "print(\"Tipos da coluna Dias Perdidos Corrigidos:\")\n",
    "checa_tipos(df[\"Dias Perdidos Corrigidos\"])\n",
    "exibe_coluna(\"Dias Perdidos Corrigidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Data da CAT'\n",
    " Considerações: Substituição de hífens e data inválida por NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui '-'por NaN\n",
    "df[\"Data da CAT\"] = df[\"Data da CAT\"].replace(\"-\", np.nan)\n",
    "\n",
    "# Substitui '19/91/2024' (data inexistente) por NaN\n",
    "df[\"Data da CAT\"] = df[\"Data da CAT\"].replace(\"19/91/2024\", np.nan)\n",
    "\n",
    "print(\"Tipos da coluna Data da CAT:\")\n",
    "checa_tipos(df[\"Data da CAT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'N° da CAT'\n",
    "\n",
    "Considerações: Conversão de ints em strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter todas as células da coluna n° da cat que são ints para string usando iterrows\n",
    "for index, row in df.iterrows():\n",
    "    if type(row[\"N° da CAT\"]) == int:\n",
    "        df.at[index, \"N° da CAT\"] = str(row[\"N° da CAT\"])\n",
    "\n",
    "print(\"Tipos da coluna N° da CAT:\")\n",
    "checa_tipos(df[\"N° da CAT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Agente Causador'\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula, remoção de códigos avulsos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Agente Causador\"] = df[\"Agente Causador\"].apply(formata_string)\n",
    "df[\"Agente Causador\"] = df[\"Agente Causador\"].apply(formata_string)\n",
    "\n",
    "print(\"Tipos da coluna Agente Causador:\")\n",
    "checa_tipos(df[\"Agente Causador\"])\n",
    "\n",
    "# Remove strings que comecam com um numero e hifen com regex, exemplo: 303010900 - ferramenta manual sem forca motriz.\n",
    "df[\"Agente Causador\"] = df[\"Agente Causador\"].str.replace(\n",
    "    r\"^\\d+ - \", \"\", regex=True)\n",
    "exibe_coluna(\"Agente Causador\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Tipo de Lesão'\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Tipo de Lesão\"] = df[\"Tipo de Lesão\"].apply(formata_string)\n",
    "df[\"Tipo de Lesão\"] = df[\"Tipo de Lesão\"].apply(formata_string)\n",
    "\n",
    "print(\"Tipos da coluna Tipo de Lesão:\")\n",
    "checa_tipos(df[\"Tipo de Lesão\"])\n",
    "\n",
    "df[\"Tipo de Lesão\"] = df[\"Tipo de Lesão\"].str.replace(\n",
    "    r\"^\\d+ - \", \"\", regex=True)\n",
    "\n",
    "df[\"Tipo de Lesão\"] = df[\"Tipo de Lesão\"].str.replace(\n",
    "    r\"^\\d+ - \", \"\", regex=True)\n",
    "exibe_coluna(\"Tipo de Lesão\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Parte do Corpo Atingida'\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Parte do Corpo Atingida\"] = df[\"Parte do Corpo Atingida\"].apply(\n",
    "    formata_string)\n",
    "df[\"Parte do Corpo Atingida\"] = df[\"Parte do Corpo Atingida\"].apply(\n",
    "    formata_string)\n",
    "\n",
    "print(\"Tipos da coluna Parte do Corpo Atingida:\")\n",
    "checa_tipos(df[\"Parte do Corpo Atingida\"])\n",
    "\n",
    "df[\"Parte do Corpo Atingida\"] = df[\"Parte do Corpo Atingida\"].str.replace(\n",
    "    r\"^\\d+ - \", \"\", regex=True\n",
    ")\n",
    "\n",
    "\n",
    "df[\"Parte do Corpo Atingida\"] = df[\"Parte do Corpo Atingida\"].str.replace(\n",
    "    r\"^\\d+ - \", \"\", regex=True\n",
    ")\n",
    "\n",
    "exibe_coluna(\"Parte do Corpo Atingida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Gravidade'\n",
    "\n",
    "Considerações: Remoção de acentos e formatação para letra minúscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gravidade\"] = df[\"Gravidade\"].apply(formata_string)\n",
    "df[\"Gravidade\"] = df[\"Gravidade\"].apply(formata_string)\n",
    "\n",
    "print(\"Tipos da coluna Gravidade:\")\n",
    "checa_tipos(df[\"Gravidade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna 'Potencial'\n",
    "Considerações: Sem alterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tipos da coluna Potencial:\")\n",
    "checa_tipos(df[\"Potencial\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Grau de Risco\n",
    "\n",
    "Considerações: foi feito um label encoding para a informação poder ser traduzida de maneira mais computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Grau de Risco\"].value_counts(dropna=False))\n",
    "# como temos três strings de escala, podemos aplicar ordinal encoding para substituir por números\n",
    "# 1 - baixo, 2 - médio, 3 - alto\n",
    "\n",
    "subs = {\n",
    "    \"Baixo\": 1,\n",
    "    \"Médio\": 2,\n",
    "    \"Alto\": 3,\n",
    "}\n",
    "\n",
    "df[\"Grau de Risco\"].replace(subs, inplace=True)\n",
    "\n",
    "print(df[\"Grau de Risco\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Plano de ação\n",
    "\n",
    "Considerações: foi feito um label encoding para a informação poder ser traduzida de maneira mais computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Plano de ação\"].value_counts(dropna=False))\n",
    "# temos três classificações realmente únicas na coluna: concluído, pendente e em andamento\n",
    "# utilizamos label encoding para atribuir um numero unico para cada\n",
    "# 1 - pendente, 2 - em andamento, 3 - concluido\n",
    "\n",
    "subs = {\n",
    "    \"Pendente\": 1,\n",
    "    \"Em andamento\": 2,\n",
    "    \"Concluído\": 3,\n",
    "    \"SIM\": 3,\n",
    "    \"Concluido\": 3,\n",
    "}\n",
    "\n",
    "# df[\"Plano de ação\"].replace(subs[\"Plano de ação\"],inplace=True)\n",
    "df[\"Plano de ação\"].replace(subs, inplace=True)\n",
    "\n",
    "print(df[\"Plano de ação\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Relatório de Investigação\n",
    "\n",
    "Considerações: Foi feito um label encoding para a informação poder ser traduzida de maneira mais computacional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - não enviado, 1 - concluido, 2 - pendente, 3 - em investigação\n",
    "\n",
    "subs = {\n",
    "    \"Não\": 0,\n",
    "    \"Concluído\": 1,\n",
    "    \"Concluido\": 1,\n",
    "    \"SIM\": 1,\n",
    "    \"Sim\": 1,\n",
    "    \"Pendente\": 2,\n",
    "    \"Em Andamento\": 3,\n",
    "    \"Em andamento\": 3,\n",
    "    \"Em investigação\": 3,\n",
    "}\n",
    "\n",
    "df[\"Relatório de Investigação\"].replace(subs, inplace=True)\n",
    "\n",
    "print(df[\"Relatório de Investigação\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Cartão Alerta\n",
    "\n",
    "Considerações: foi feito um label encoding para a informação poder ser traduzida de maneira mais computacional, além de criar uma nova coluna com dados mais detalhados para os casos onde esta era uma solução mais apropriada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Cartão Alerta\"].value_counts(dropna=False))\n",
    "# 0 - não enviado, 1 - enviado, 2 - em revisão\n",
    "\n",
    "subs = {\n",
    "    \"Não enviado\": 0,\n",
    "    \"SIM\": 1,\n",
    "    \"Sim\": 1,\n",
    "    \"Em revisão\": 2,\n",
    "}\n",
    "\n",
    "df[\"Cartão Alerta\"].replace(subs, inplace=True)\n",
    "# transformamos texto descritivo em nova coluna\n",
    "df[\"Cartão Alerta\"] = df[\"Cartão Alerta\"].apply(\n",
    "    lambda x: 1 if isinstance(x, str) else x\n",
    ")\n",
    "# print(df[\"Cartão Alerta\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Compromissos (Regra de Ouro)\n",
    "\n",
    "Considerações: foi feito um label encoding utilizando diretamente a numeração aplicada já na tabela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Compromissos (Regra de Ouro)\"].value_counts(dropna=False))\n",
    "# 0 - Outros, 1 - Álcool e Drogas, 2 - Percepção de Risco, 3 - Trabalho em Altura, 4 - Eletricidade, 5 - Espaço Confinado, 6 - Linha de Perigo\n",
    "# 7 - Bloqueio e Proteção, 8 - Veículos e Equipamentos Móveis, 9 - Trabalho a Quente, 10 - Produtos Químicos Perigosos, 11 - Não se Aplica\n",
    "df[\"Compromissos (Regra de Ouro)\"].replace(\n",
    "    \"Outros\", \"0 - Outros\", inplace=True)\n",
    "df[\"Compromissos (Regra de Ouro)\"] = df[\"Compromissos (Regra de Ouro)\"].apply(\n",
    "    lambda x: int(x[:2]) if isinstance(x, str) else np.nan\n",
    ")\n",
    "\n",
    "print(df[\"Compromissos (Regra de Ouro)\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colunas Causa raiz 1-8\n",
    "\n",
    "Considerações: feita limpeza simples adicionando NaN no lugar de strings vazias ou coisas do tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAntes de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 1\"].unique():\n",
    "    print(elem)\n",
    "\n",
    "df[\"Causa raiz 1\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 1\"] = df[\"Causa raiz 1\"].apply(\n",
    "    lambda x: unidecode(x.lower().strip(\n",
    "        \"\\n\")) if isinstance(x, str) else np.nan\n",
    ")  # adicionando NaN no lugar de vazio\n",
    "\n",
    "print(\"\\nDepois de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 1\"].unique():\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAntes de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 2\"].unique():\n",
    "    print(elem)\n",
    "\n",
    "\n",
    "df[\"Causa raiz 2\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 2\"] = df[\"Causa raiz 2\"].apply(\n",
    "    lambda x: unidecode(x.lower().strip(\n",
    "        \"\\n\")) if isinstance(x, str) else np.nan\n",
    ")\n",
    "\n",
    "print(\"\\nDepois de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 2\"].unique():\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAntes de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 3\"].unique():\n",
    "    print(elem)\n",
    "\n",
    "df[\"Causa raiz 3\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 3\"] = df[\"Causa raiz 3\"].apply(\n",
    "    lambda x: unidecode(x.lower().strip(\n",
    "        \"\\n\")) if isinstance(x, str) else np.nan\n",
    ")\n",
    "\n",
    "print(\"\\nDepois de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 3\"].unique():\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAntes de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 4\"].unique():\n",
    "    print(elem)\n",
    "\n",
    "df[\"Causa raiz 4\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 4\"] = df[\"Causa raiz 4\"].apply(\n",
    "    lambda x: unidecode(x.lower().strip(\n",
    "        \"\\n\")) if isinstance(x, str) else np.nan\n",
    ")\n",
    "\n",
    "print(\"\\nDepois de limpar:\\n\\n\")\n",
    "for elem in df[\"Causa raiz 4\"].unique():\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Causa raiz 5\"].value_counts(dropna=False))\n",
    "\n",
    "df[\"Causa raiz 5\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 5\"] = df[\"Causa raiz 5\"].apply(\n",
    "    lambda x: (\n",
    "        unidecode(x.lower().strip(\".\").strip(\"\\n\")\n",
    "                  ) if isinstance(x, str) else np.nan\n",
    "    )\n",
    ")\n",
    "print(df[\"Causa raiz 5\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Causa raiz 6\"].value_counts(dropna=False))\n",
    "# como temos hífens representando NaN, trocamos por NaN para padronizar\n",
    "df[\"Causa raiz 6\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 6\"].replace(\n",
    "    \"Falha na Supervsão\", \"Falha na supervisão\", inplace=True)\n",
    "df[\"Causa raiz 6\"].replace(\n",
    "    \"Configuração doo sistema\", \"Configuração do sistema\", inplace=True\n",
    ")\n",
    "df[\"Causa raiz 6\"] = df[\"Causa raiz 6\"].apply(\n",
    "    lambda x: unidecode(x.lower().strip(\".\")) if isinstance(x, str) else np.nan\n",
    ")\n",
    "\n",
    "print(df[\"Causa raiz 6\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Causa raiz 7\"].value_counts(dropna=False))\n",
    "# como temos hífens representando NaN, trocamos por NaN para padronizar\n",
    "df[\"Causa raiz 7\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 7\"] = df[\"Causa raiz 7\"].apply(\n",
    "    lambda x: unidecode(x.lower().strip(\".\")) if isinstance(x, str) else np.nan\n",
    ")\n",
    "subs[\"Causa raiz 7\"] = \"- trocado por NaN\"\n",
    "\n",
    "print(df[\"Causa raiz 7\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Causa raiz 8\"].value_counts(dropna=False))\n",
    "# como temos hífens representando NaN, trocamos por NaN para padronizar\n",
    "df[\"Causa raiz 8\"].replace(\"-\", np.nan, inplace=True)\n",
    "df[\"Causa raiz 8\"] = df[\"Causa raiz 8\"].apply(\n",
    "    lambda x: unidecode(x.lower().strip(\".\")) if isinstance(x, str) else np.nan\n",
    ")\n",
    "subs[\"Causa raiz 8\"] = \"- trocado por NaN\"\n",
    "\n",
    "print(df[\"Causa raiz 8\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descobrindo se alguma coluna só tem NaN e removendo do dataframe\n",
    "for name in df:\n",
    "    if df[name].isna().sum() == len(df[name]):\n",
    "        print(\"Coluna %s removida\" % (name))\n",
    "        remove_coluna(df, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna chave foi removida porque só tinha valores NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coluna Local de instalação\n",
    "Considerações: Pelas coordenadas, pegaremos os locais de instalação mais perto daquela coordenada calculando com a fórmula de haversine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os locais de instalacao\n",
    "df = calcula_local_instalacao_acidente(\n",
    "    50, df, dataFrameInstalacao  # raio arbitrario de 50 km\n",
    ")\n",
    "df[\"Local de instalação\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como inicialmente estamos fazendo so para Eletrosul, temos que checar se alguma outra empresa esta tendo um local de instalacao erroneamente. Futuramente, quando usaremos dados de todas as empresa, esse passo sera desnecessario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checar_acidente_fora_eletrosul(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversão de dataframe pandas para csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerações: Para colocar em csv, primeiramente temos que decidir um caracter para separar as colunas, e para decidir tal caracter nao pode estar um alguma das linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checar se o DataFrame contém o caractere '|'\n",
    "if possui_pipe(df):\n",
    "    print(\"O DataFrame contém o caractere '|'.\")\n",
    "else:\n",
    "    print(\"O DataFrame pode ser salvo em csv.\")\n",
    "\n",
    "# Exibir DataFrame original\n",
    "print(\"DataFrame original:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\n",
    "    pathUtil + \"acidentes/\" + \"BD_Acidentes_Padronizado.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    "    sep=\"|\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
