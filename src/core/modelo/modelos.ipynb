{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                            confusion_matrix, ConfusionMatrixDisplay,\n",
    "                            make_scorer)\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, LeavePOut, cross_val_predict, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/util/\"\n",
    "path = ajuste_path(path)\n",
    "\n",
    "df = pd.read_csv(path + \"dataset_treinamento.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o dataframe para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding do local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# locais antes do encoding\n",
    "print(df[\"Local de instalação\"].nunique())\n",
    "\n",
    "df[\"local encoded\"] = label_encoder.fit_transform(df[\"Local de instalação\"])\n",
    "df = df.drop(columns=[\"Local de instalação\"])\n",
    "\n",
    "# locais encoded\n",
    "print(df[\"local encoded\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo as colunas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.rename(columns={\"Binario Acidentes de Alto Potencial\": \"Alto Potencial\"}, inplace=True)\n",
    "\n",
    "# teste\n",
    "print(df[\"binario acidentes\"].value_counts())\n",
    "print(df[\"Quantidade de Acidentes\"].sum())\n",
    "\n",
    "columns = [\"Ano\", \"Mes\", \"HH total\", \"local encoded\", \"binario acidentes\"]\n",
    "df = df[columns]\n",
    "\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlação entre as colunas escolhidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(columns=\"Ano\").corr()\n",
    "\n",
    "# list(plt.colormaps)\n",
    "sns.heatmap(corr, cmap='RdBu', annot=True, vmin=-1, vmax=1)\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo as features e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [\"Ano\", \"Mes\", \"HH total\", \"local encoded\"]\n",
    "y_column = \"binario acidentes\"\n",
    "\n",
    "X = df[X_columns]\n",
    "y = df[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        },\n",
    "    \"Linear Discriminant Analysis\": {\n",
    "        \"model\": LinearDiscriminantAnalysis(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        },\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(probability=True, class_weight=\"balanced\"),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        },\n",
    "    \"Naive Bayes\": {\n",
    "        \"model\": GaussianNB(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        },\n",
    "    \"GBM\": {\n",
    "        \"model\":  GradientBoostingClassifier(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\"),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "loo = LeaveOneOut()\n",
    "lpo = LeavePOut(p=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=[\"Ano\"], axis=1)\n",
    "for model_name, m in models.items():\n",
    "    model = m[\"model\"]\n",
    "    threshold = 0.5\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    m[\"probs\"] = cross_val_predict(model, X, y, cv=kfold, method=\"predict_proba\")[:, 1]\n",
    "    m[\"preds\"] = (m[\"probs\"] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição normal das probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, m in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    max = m[\"probs\"].max()\n",
    "    freq_probs = pd.Series(m[\"probs\"]).value_counts(bins=np.arange(0, max + 0.01, 0.01)).sort_index()\n",
    "    print(freq_probs[freq_probs > 0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação das métricas básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model, y_pred in y_preds.items():\n",
    "#     accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "#     precision = precision_score(y_true=y_test, y_pred=y_pred, average=\"binary\")\n",
    "#     recall = recall_score(y_true=y_test, y_pred=y_pred, average=\"binary\")\n",
    "#     f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"binary\")\n",
    "\n",
    "#     cm = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "#     # print(f\"Accuracy: {accuracy:.2f}\")\n",
    "#     print(f\"Precision: {precision:.2f}\")\n",
    "#     print(f\"Recall: {recall:.2f}\")\n",
    "#     print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "#     cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negativo\", \"Positivo\"])\n",
    "#     cm_disp.plot(cmap=\"Blues\")\n",
    "\n",
    "#     plt.title(model)\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
