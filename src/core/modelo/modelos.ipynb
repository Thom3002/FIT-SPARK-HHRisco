{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, confusion_matrix,\n",
    "                             f1_score, precision_score, recall_score)\n",
    "from sklearn.model_selection import (LeaveOneOut, LeavePOut, StratifiedKFold,\n",
    "                                     cross_val_predict)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/util/\"\n",
    "path = ajuste_path(path)\n",
    "\n",
    "df = pd.read_csv(path + \"dataset_treinamento.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o dataframe para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding do local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# locais antes do encoding\n",
    "print(df[\"Local de instalação\"].nunique())\n",
    "\n",
    "df[\"local encoded\"] = label_encoder.fit_transform(df[\"Local de instalação\"])\n",
    "df = df.drop(columns=[\"Local de instalação\"])\n",
    "\n",
    "# locais encoded\n",
    "print(df[\"local encoded\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo as colunas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"binario acidentes\"].value_counts())\n",
    "print(df[\"Quantidade de Acidentes\"].sum())\n",
    "\n",
    "columns = [\"Ano\", \"Mes\", \"HH total\", \"local encoded\", \"binario acidentes\"]\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlação entre as colunas escolhidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(columns=\"Ano\").corr()\n",
    "\n",
    "# list(plt.colormaps)\n",
    "sns.heatmap(corr, cmap='RdBu', annot=True, vmin=-1, vmax=1)\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo as features e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [\"Ano\", \"Mes\", \"HH total\",\n",
    "             \"local encoded\", \"Temp_Mean\", \"Precipitation_Sum\"]\n",
    "y_column = \"binario acidentes\"\n",
    "\n",
    "X = df[X_columns]\n",
    "y = df[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": LogisticRegression(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "    },\n",
    "    \"Linear Discriminant Analysis\": {\n",
    "        \"model\": LinearDiscriminantAnalysis(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(probability=True, class_weight=\"balanced\"),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        \"model\": GaussianNB(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "    },\n",
    "    \"GBM\": {\n",
    "        \"model\":  GradientBoostingClassifier(),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\"),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "loo = LeaveOneOut()\n",
    "lpo = LeavePOut(p=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=[\"Ano\"], axis=1)\n",
    "for model_name, m in models.items():\n",
    "    model = m[\"model\"]\n",
    "    threshold = 0.5\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    m[\"probs\"] = cross_val_predict(\n",
    "        model, X, y, cv=skfold, method=\"predict_proba\")[:, 1]\n",
    "    m[\"preds\"] = (m[\"probs\"] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição normal das probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, m in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    max = m[\"probs\"].max()\n",
    "    freq_probs = pd.Series(m[\"probs\"]).value_counts(\n",
    "        bins=np.arange(0, max + 0.01, 0.01)).sort_index()\n",
    "    print(freq_probs[freq_probs > 0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação das métricas básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, m in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Precision: {precision_score(y, m['preds'])}\")\n",
    "    print(f\"Recall: {recall_score(y, m['preds'])}\")\n",
    "    print(f\"F1 Score: {f1_score(y, m['preds'])}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true=y, y_pred=m[\"preds\"])\n",
    "\n",
    "    cm_disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm, display_labels=[\"Negativo\", \"Positivo\"])\n",
    "    cm_disp.plot(cmap=\"Blues\")\n",
    "\n",
    "    plt.title(model_name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
