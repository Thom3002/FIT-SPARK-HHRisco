{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, confusion_matrix,\n",
    "                             f1_score, precision_score, recall_score)\n",
    "from sklearn.model_selection import (GridSearchCV, LeaveOneOut, LeavePOut,\n",
    "                                     StratifiedKFold, cross_val_predict)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (LabelEncoder, MaxAbsScaler, MinMaxScaler,\n",
    "                                   Normalizer, PowerTransformer,\n",
    "                                   QuantileTransformer, RobustScaler,\n",
    "                                   StandardScaler)\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração para não exibir os warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/util/\"\n",
    "path = ajuste_path(path)\n",
    "\n",
    "df = pd.read_csv(path + \"dataset_treinamento.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o dataframe para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding do local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# locais antes do encoding\n",
    "print(df[\"Local de instalação\"].nunique())\n",
    "\n",
    "df[\"local encoded\"] = label_encoder.fit_transform(df[\"Local de instalação\"])\n",
    "df = df.drop(columns=[\"Local de instalação\"])\n",
    "\n",
    "# locais encoded\n",
    "print(df[\"local encoded\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo as colunas utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"binario acidentes\"].value_counts())\n",
    "print(df[\"Quantidade de Acidentes\"].sum())\n",
    "\n",
    "columns = [\"Ano\", \"Mes\", \"HH total\", \"local encoded\", \"binario acidentes\"]\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de correlação entre as colunas escolhidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(columns=\"Ano\").corr()\n",
    "\n",
    "sns.heatmap(corr, cmap='RdBu', annot=True, vmin=-1, vmax=1)\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo os datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo as features e o target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = [\"Ano\", \"Mes\", \"HH total\",\n",
    "             \"local encoded\"]\n",
    "y_column = \"binario acidentes\"\n",
    "\n",
    "X = df[X_columns]\n",
    "y = df[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [None, StandardScaler(), MinMaxScaler(), MaxAbsScaler(),\n",
    "           RobustScaler(), Normalizer(), QuantileTransformer(), PowerTransformer()]\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"model\": Pipeline([\n",
    "            ('scaler', None),\n",
    "            ('clf', LogisticRegression())\n",
    "        ]),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        \"params\": {\n",
    "            'scaler': scalers,\n",
    "            'clf__C': [0.01, 0.05, 0.1, 1, 5],\n",
    "            'clf__max_iter': [100, 1000, 10000],\n",
    "            'clf__class_weight': [\"balanced\", None],\n",
    "        },\n",
    "        \"best_params\": {}\n",
    "    },\n",
    "    \"Linear Discriminant Analysis\": {\n",
    "        \"model\": Pipeline([\n",
    "            ('scaler', None),\n",
    "            ('clf', LinearDiscriminantAnalysis())\n",
    "        ]),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        \"params\": {\n",
    "            'scaler': scalers,\n",
    "            'clf__solver': [\"svd\", \"lsqr\", \"eigen\"],\n",
    "            'clf__n_components': [None, 1],\n",
    "        },\n",
    "        \"best_params\": {}\n",
    "    },\n",
    "    \"SVC\": {\n",
    "        \"model\": Pipeline([\n",
    "            ('scaler', None),\n",
    "            ('clf', SVC(probability=True))\n",
    "        ]),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        \"params\": {\n",
    "            'scaler': scalers,\n",
    "            'clf__class_weight': [\"balanced\", None],\n",
    "            'clf__C': [0.01, 0.1, 1],\n",
    "            'clf__kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "        },\n",
    "        \"best_params\": {}\n",
    "    },\n",
    "    \"Naive Bayes\": {\n",
    "        \"model\": Pipeline([\n",
    "            ('scaler', None),\n",
    "            ('clf', GaussianNB())\n",
    "        ]),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        \"params\": {\n",
    "            'scaler': scalers,\n",
    "            'clf__var_smoothing': [1e-9, 1e-8, 1e-7],\n",
    "        },\n",
    "        \"best_params\": {}\n",
    "    },\n",
    "    \"GBM\": {\n",
    "        \"model\": Pipeline([\n",
    "            ('scaler', None),\n",
    "            ('clf', GradientBoostingClassifier())\n",
    "        ]),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        \"params\": {\n",
    "            'scaler': scalers,\n",
    "            'clf__n_estimators': [50, 100, 150, 200, 250],\n",
    "            'clf__learning_rate': [0.01, 0.1, 1],\n",
    "            'clf__max_depth': [1, 3, 5, 7, None],\n",
    "        },\n",
    "        \"best_params\": {}\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": Pipeline([\n",
    "            ('scaler', None),\n",
    "            ('clf', RandomForestClassifier())\n",
    "        ]),\n",
    "        \"probs\": [],\n",
    "        \"preds\": [],\n",
    "        \"params\": {\n",
    "            'scaler': scalers,\n",
    "            'clf__n_estimators': [50, 100, 150, 200, 250],\n",
    "            'clf__max_depth': [1, 3, 5, 7, None],\n",
    "            'clf__class_weight': [\"balanced\", None],\n",
    "        },\n",
    "        \"best_params\": {}\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    columns=[\"Model\", \"Best Params\", \"F1\", \"Precision\", \"Recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model[\"best_params\"] != {}:\n",
    "        continue\n",
    "\n",
    "    print(f\"GridSearch: {model_name}\")\n",
    "    grid_search = GridSearchCV(\n",
    "        model[\"model\"], model[\"params\"], cv=skfold, scoring=\"f1\", n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    model[\"best_params\"] = grid_search.best_params_\n",
    "\n",
    "    result = {\n",
    "        \"Model\": model_name,\n",
    "        \"Best Params\": grid_search.best_params_,\n",
    "        \"F1\": grid_search.best_score_,\n",
    "    }\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([result])])\n",
    "\n",
    "    print(\"Model: \", model_name)\n",
    "    print(\"Best Params:\", model[\"best_params\"])\n",
    "\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(path + \"predicao/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino e Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}\")\n",
    "    model[\"model\"].set_params(**model[\"best_params\"])\n",
    "    print(model[\"model\"].get_params())\n",
    "\n",
    "    model[\"probs\"] = cross_val_predict(\n",
    "        model[\"model\"], X, y, cv=skfold, method=\"predict_proba\")[:, 1]\n",
    "\n",
    "    model[\"preds\"] = (model[\"probs\"] >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição normal das probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, m in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "\n",
    "    max = m[\"probs\"].max()\n",
    "    freq_probs = pd.Series(m[\"probs\"]).value_counts(\n",
    "        bins=np.arange(0, max + 0.01, 0.01)).sort_index()\n",
    "    print(freq_probs[freq_probs > 0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliação das métricas básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, m in models.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Precision: {precision_score(y, m['preds'])}\")\n",
    "    print(f\"Recall: {recall_score(y, m['preds'])}\")\n",
    "    print(f\"F1 Score: {f1_score(y, m['preds'])}\")\n",
    "\n",
    "    cm = confusion_matrix(y_true=y, y_pred=m[\"preds\"])\n",
    "\n",
    "    cm_disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm, display_labels=[\"Negativo\", \"Positivo\"])\n",
    "    cm_disp.plot(cmap=\"Blues\")\n",
    "\n",
    "    plt.title(model_name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
