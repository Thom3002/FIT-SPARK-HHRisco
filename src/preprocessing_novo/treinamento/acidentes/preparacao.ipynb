{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de preparação do dataset de Acidentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura do dataset de entrada pre-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/\"\n",
    "path = ajuste_path(path)\n",
    "\n",
    "pathUtil = path + \"util/\"\n",
    "\n",
    "df_acidentes_padronizado = pd.read_csv(\n",
    "    pathUtil + \"acidentes/\" + \"acidentes_preprocessado.csv\", encoding=\"utf-8\", delimiter=\"@\"\n",
    ")\n",
    "\n",
    "df_acidentes_padronizado.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenando por tempo(mais antigo é o primeiro) e criando coluna data com nível de detalhe em hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenchendo com 12 horas o que está nan para não perder a singularidade da hora\n",
    "df_acidentes_padronizado[\"hora\"] = df_acidentes_padronizado[\"hora\"].fillna(12)\n",
    "\n",
    "valores = df_acidentes_padronizado[\"hora\"].unique()\n",
    "\n",
    "subs = {}\n",
    "for hora in valores:\n",
    "    try:\n",
    "        subs[hora] = hora[:2]\n",
    "    except:\n",
    "        # subs['Hora'][np.nan] = 'nao informado'\n",
    "        pass\n",
    "\n",
    "print(json.dumps(subs, indent=4))\n",
    "\n",
    "df_acidentes_padronizado[\"hora\"] = df_acidentes_padronizado[\"hora\"].replace(\n",
    "    subs)\n",
    "\n",
    "# Criando coluna \"Data\" a partir das colunas 'day', 'month' e 'year'\n",
    "df_acidentes_padronizado['data'] = pd.to_datetime(\n",
    "    df_acidentes_padronizado[['ano', 'mes', 'dia', 'hora']].rename(\n",
    "        columns={'ano': 'year', 'mes': 'month', 'dia': 'day', 'hora': 'hour'}\n",
    "    ))\n",
    "\n",
    "# Ordenando o dataframe pelas datas, do mais antigo para o mais recente\n",
    "df_acidentes_padronizado = df_acidentes_padronizado.sort_values(by='data')\n",
    "\n",
    "# Renomeando as colunas de volta\n",
    "df_acidentes_padronizado.rename(\n",
    "    columns={'day': 'dia', 'month': 'mes', 'year': 'ano'}, inplace=True)\n",
    "\n",
    "# Reset do index\n",
    "df_acidentes_padronizado = df_acidentes_padronizado.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o indice dos acidentes originais antes de retirar algumas categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma nova coluna \"Indice acidente\" com o valor do índice de cada linha\n",
    "df_acidentes_padronizado['indice acidente'] = [\n",
    "    i for i in df_acidentes_padronizado.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo acidentes de terceiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linhas antes da remoção de terceiros: \",\n",
    "      df_acidentes_padronizado.shape[0])\n",
    "qtd_linhas_com_terceiros = df_acidentes_padronizado[\n",
    "    df_acidentes_padronizado[\"empregado\"] == \"terceiro\"\n",
    "].shape[0]\n",
    "\n",
    "print(\"Removendo \" + str(qtd_linhas_com_terceiros) + \" linhas com terceiros\")\n",
    "\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    df_acidentes_padronizado['empregado'] == 'proprio']\n",
    "\n",
    "print(\"Linhas após a remoção de terceiros: \",\n",
    "      df_acidentes_padronizado.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo linhas cuja Classificação é de trajeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contando quantas linhas possuem \"trajeto\" na coluna Classificação\n",
    "conta_linhas_trajeto = (\n",
    "    df_acidentes_padronizado[\"classificacao\"].str.contains(\"trajeto\").sum()\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas que possuem 'trajeto' na coluna Classificação: {conta_linhas_trajeto} de {df_acidentes_padronizado.shape[0]} linhas totais.\"\n",
    ")\n",
    "\n",
    "# removendo as linhas que possuem \"trajeto\" na coluna Classificação\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    ~df_acidentes_padronizado[\"classificacao\"].str.contains(\"trajeto\")\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas após a remoção: {df_acidentes_padronizado.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo acidentes que ocorreram em alguma empresa que não é a Eletrosul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    df_acidentes_padronizado[\"empresa\"] == \"cgt eletrosul\"\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas após a remoção: {df_acidentes_padronizado.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo acidentes sem ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_nans_id = df_acidentes_padronizado[\"id\"].isna().sum()\n",
    "\n",
    "print(\"Quantidade de NaNs na coluna ID:\", qtd_nans_id)\n",
    "\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    (~df_acidentes_padronizado[\"id\"].isna()) & (\n",
    "        df_acidentes_padronizado[\"id\"] != '-')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminação das linhas de acidentes irrelevantes e de predisposição física"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Quantidade de linhas antes a remoção: {df_acidentes_padronizado.shape[0]}\")\n",
    "\n",
    "# Valores da coluna \"Indice acidente\" dos acidentes que foram julgados irrelevantes\n",
    "acidentes_irrelevantes = [56, 102, 171, 206,\n",
    "                          213, 294, 489, 667, 703, 788, 810, 844]\n",
    "\n",
    "# Valores da coluna \"Indice acidente\" dos acidentes com causa relacionada à predisposição física do empregado\n",
    "acidentes_por_predisposicao_fisica = [\n",
    "    86, 179, 182, 205, 250, 257, 341, 443, 496]\n",
    "\n",
    "# Eliminando acidentes_irrelevantes\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[~df_acidentes_padronizado[\"indice acidente\"].isin(\n",
    "    acidentes_irrelevantes)]\n",
    "\n",
    "# Eliminando acidentes_por_predisposicao_fisica\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[~df_acidentes_padronizado[\"indice acidente\"].isin(\n",
    "    acidentes_por_predisposicao_fisica)]\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas após a remoção: {df_acidentes_padronizado.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando quais colunas ficarão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['classificacao', 'id', 'data', 'descricao', 'latitude', 'longitude']\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o novo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataset no folder modificados\n",
    "df_acidentes_padronizado.to_csv(\n",
    "    pathUtil + \"acidentes/\" + \"acidentes_preparado.csv\",\n",
    "    sep=\"@\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
