{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook de preparação do dataset de Acidentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from resolve_path import ajuste_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura do dataset de entrada pre-processado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/util/\"\n",
    "path = ajuste_path(path)\n",
    "\n",
    "df_acidentes_padronizado = pd.read_csv(\n",
    "    path + \"acidentes/\" + \"acidentes_preprocessado.csv\", encoding=\"utf-8\", sep=\"#\"\n",
    ")\n",
    "\n",
    "df_acidentes_padronizado.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma nova coluna \"Indice acidente\" com o valor do índice de cada linha\n",
    "df_acidentes_padronizado['indice acidente'] = [\n",
    "    i for i in df_acidentes_padronizado.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenando por tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando o dataframe pelas datas, do mais antigo para o mais recente\n",
    "df_acidentes_padronizado = df_acidentes_padronizado.sort_values(by='data')\n",
    "\n",
    "# Reset do index\n",
    "df_acidentes_padronizado = df_acidentes_padronizado.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o indice dos acidentes originais antes de retirar algumas categorias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo acidentes de terceiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linhas antes da remoção de terceiros: \",\n",
    "      df_acidentes_padronizado.shape[0])\n",
    "qtd_linhas_com_terceiros = df_acidentes_padronizado[\n",
    "    df_acidentes_padronizado[\"empregado\"] == \"terceiro\"\n",
    "].shape[0]\n",
    "\n",
    "print(\"Removendo \" + str(qtd_linhas_com_terceiros) + \" linhas com terceiros\")\n",
    "\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    df_acidentes_padronizado['empregado'] == 'proprio']\n",
    "\n",
    "print(\"Linhas após a remoção de terceiros: \",\n",
    "      df_acidentes_padronizado.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo linhas cuja Classificação é de trajeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contando quantas linhas possuem \"trajeto\" na coluna Classificação\n",
    "conta_linhas_trajeto = (\n",
    "    df_acidentes_padronizado[\"classificacao\"].str.contains(\"trajeto\").sum()\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas que possuem 'trajeto' na coluna Classificação: {conta_linhas_trajeto} de {df_acidentes_padronizado.shape[0]} linhas totais.\"\n",
    ")\n",
    "\n",
    "# removendo as linhas que possuem \"trajeto\" na coluna Classificação\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    ~df_acidentes_padronizado[\"classificacao\"].str.contains(\"trajeto\")\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas após a remoção: {df_acidentes_padronizado.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo acidentes que ocorreram em alguma empresa que não é a Eletrosul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    df_acidentes_padronizado[\"empresa\"] == \"cgt eletrosul\"\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas após a remoção: {df_acidentes_padronizado.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo acidentes sem ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_nans_id = df_acidentes_padronizado[\"id\"].isna().sum()\n",
    "\n",
    "print(\"Quantidade de NaNs na coluna ID:\", qtd_nans_id)\n",
    "\n",
    "df_acidentes_padronizado = df_acidentes_padronizado[\n",
    "    (~df_acidentes_padronizado[\"id\"].isna()) & (\n",
    "        df_acidentes_padronizado[\"id\"] != '-')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminação das linhas de acidentes irrelevantes e de predisposição física"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Quantidade de linhas antes a remoção: {df_acidentes_padronizado.shape[0]}\")\n",
    "\n",
    "acidentes_irrelevantes = [\n",
    "    {\"id\": 1540378, \"data\": \"2021-01-08 09:00:00\"},\n",
    "    {\"id\": 1542316, \"data\": \"2021-08-10 07:00:00\"},\n",
    "    {\"id\": 1539115, \"data\": \"2022-04-20 10:00:00\"},\n",
    "    {\"id\": 1532135, \"data\": \"2022-08-19 14:00:00\"},\n",
    "    {\"id\": 1533092, \"data\": \"2023-07-16 12:00:00\"},\n",
    "    {\"id\": 1541615, \"data\": \"2024-02-07 09:00:00\"},\n",
    "    {\"id\": 210344, \"data\": \"2024-03-01 08:00:00\"},\n",
    "    {\"id\": 9002643, \"data\": \"2024-03-22 14:00:00\"},\n",
    "    {\"id\": 9002552, \"data\": \"2023-05-29 11:00:00\"},\n",
    "    {\"id\": 1523324, \"data\": \"2023-07-25 10:00:00\"},\n",
    "]\n",
    "\n",
    "id_acidentes_irrelevantes = [acidente[\"id\"]\n",
    "                             for acidente in acidentes_irrelevantes]\n",
    "data_acidentes_irrelevantes = [acidente[\"data\"]\n",
    "                               for acidente in acidentes_irrelevantes]\n",
    "\n",
    "df_acidentes_padronizado[\"id\"] = df_acidentes_padronizado[\"id\"].astype(int)\n",
    "\n",
    "df_acidentes_padronizado = df_acidentes_padronizado.loc[~\n",
    "                                                        (df_acidentes_padronizado[\"id\"].isin(id_acidentes_irrelevantes)\n",
    "                                                         & df_acidentes_padronizado[\"data\"].isin(data_acidentes_irrelevantes))\n",
    "                                                        ]\n",
    "\n",
    "print(\n",
    "    f\"Quantidade de linhas após a remoção: {df_acidentes_padronizado.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando quais colunas ficarão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['id', 'data', 'descricao', 'classificacao', 'latitude', 'longitude', 'agente causador']\n",
    "# df_acidentes_padronizado = df_acidentes_padronizado[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o novo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataset no folder modificados\n",
    "path = \"data/util/\"\n",
    "path = ajuste_path(path)\n",
    "\n",
    "df_acidentes_padronizado.to_csv(\n",
    "    path + \"acidentes/\" + \"acidentes_preparado.csv\",\n",
    "    sep=\"#\",\n",
    "    encoding=\"utf-8\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
