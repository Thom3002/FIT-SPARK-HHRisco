{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "from openmeteo_requests import Client\n",
    "from resolve_path import ajuste_path, read_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2020-02-01'\n",
    "END_DATE = '2024-06-30'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathUtil = ajuste_path('data/util/')\n",
    "pathInput = ajuste_path('data/input/')\n",
    "\n",
    "df_treinamento = pd.read_csv(pathUtil + 'dataset_treinamento_preparado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACALHAU (feito para o dataset de treinamento com os nomes das colunas antigas)\n",
    "df_treinamento.rename(columns={\n",
    "    'Local de instalação': 'local_de_instalacao',\n",
    "    'Ano': 'ano',\n",
    "    'Mes': 'mes',\n",
    "    'Latitude': 'latitude',\n",
    "    'Longitude': 'longitude'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupar o dataset de treinamento por Latitude e Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treinamento_agrupado = df_treinamento.groupby(['latitude', 'longitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifica para quais coordenadas devem ser feitas as requisições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se o csv dados_meteorologicos.csv já existe\n",
    "if os.path.exists(pathInput + 'dataset_dados_meteorologicos.csv'):\n",
    "    df_resultados = pd.read_csv(pathInput + 'dataset_dados_meteorologicos.csv')\n",
    "    # Verifica quais coordenadas estão faltando ao comparar com df_treinamento_agrupado\n",
    "    df_resultados_agrupado = df_resultados.groupby(['latitude', 'longitude'])\n",
    "    df_treinamento_agrupado = df_treinamento_agrupado.filter(\n",
    "        lambda x: (x['latitude'].iloc[0], x['longitude'].iloc[0]\n",
    "                   ) not in df_resultados_agrupado.groups\n",
    "        # Seleciona os valores unicos de latitude e longitude que sobraram\n",
    "    ).drop_duplicates(subset=['latitude', 'longitude']).groupby(['latitude', 'longitude'])\n",
    "else:\n",
    "    df_resultados = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisição da API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação de funções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtem_dados_api(latitude: float, longitude: float, start_date=START_DATE, end_date=END_DATE, max_retry=3):\n",
    "    '''\n",
    "    Obtém os dados meteorológicos diários de uma determinada coordenada geográfica (latitude, longitude) da API Open-Meteo (\"https://archive-api.open-meteo.com/v1/archive\").\n",
    "\n",
    "    Args:\n",
    "        latitude (float): Latitude da localização.\n",
    "        longitude (float): Longitude da localização.\n",
    "        start_date (str): Data de início no formato 'YYYY-MM-DD'.\n",
    "        end_date (str): Data de término no formato 'YYYY-MM-DD'.\n",
    "        max_retry (int): Número máximo de tentativas em caso de falha na requisição.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame contendo os dados meteorológicos diários.\n",
    "        None: Retorna None se todas as tentativas de requisição falharem.\n",
    "    '''\n",
    "    # Configurar a sessão da API com cache\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "    openmeteo = Client(session=cache_session)\n",
    "    url_api = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"daily\": [\"weather_code\", \"temperature_2m_max\", \"temperature_2m_min\", \"apparent_temperature_max\", \"apparent_temperature_min\", \"precipitation_sum\", \"precipitation_hours\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\", \"et0_fao_evapotranspiration\"],\n",
    "        \"timezone\": \"America/Sao_Paulo\"\n",
    "    }\n",
    "\n",
    "    count_retry = 0\n",
    "\n",
    "    while count_retry < max_retry:\n",
    "        # Fazer a solicitação da API\n",
    "        try:\n",
    "            response = openmeteo.weather_api(url_api, params=params)[0]\n",
    "            print(\n",
    "                f\"Coordenadas {response.Latitude()}°N {response.Longitude()}°E\")\n",
    "            print(\n",
    "                f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "\n",
    "            # Processamento dos dados diários\n",
    "            daily = response.Daily()\n",
    "\n",
    "            daily_weather_code = daily.Variables(0).ValuesAsNumpy()\n",
    "            daily_temperature_2m_max = daily.Variables(1).ValuesAsNumpy()\n",
    "            daily_temperature_2m_min = daily.Variables(2).ValuesAsNumpy()\n",
    "            daily_apparent_temperature_max = daily.Variables(3).ValuesAsNumpy()\n",
    "            daily_apparent_temperature_min = daily.Variables(4).ValuesAsNumpy()\n",
    "            daily_precipitation_sum = daily.Variables(5).ValuesAsNumpy()\n",
    "            daily_precipitation_hours = daily.Variables(6).ValuesAsNumpy()\n",
    "            daily_wind_speed_10m_max = daily.Variables(7).ValuesAsNumpy()\n",
    "            daily_wind_gusts_10m_max = daily.Variables(8).ValuesAsNumpy()\n",
    "            daily_et0_fao_evapotranspiration = daily.Variables(\n",
    "                9).ValuesAsNumpy()\n",
    "\n",
    "            daily_data = {\"date\": pd.date_range(\n",
    "                start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "                end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n",
    "                freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "                inclusive=\"left\"\n",
    "            )}\n",
    "\n",
    "            daily_data[\"latitude\"] = latitude\n",
    "            daily_data[\"longitude\"] = longitude\n",
    "            daily_data[\"weather_code\"] = daily_weather_code\n",
    "            daily_data[\"temperature_2m_max\"] = daily_temperature_2m_max\n",
    "            daily_data[\"temperature_2m_min\"] = daily_temperature_2m_min\n",
    "            daily_data[\"apparent_temperature_max\"] = daily_apparent_temperature_max\n",
    "            daily_data[\"apparent_temperature_min\"] = daily_apparent_temperature_min\n",
    "            daily_data[\"precipitation_sum\"] = daily_precipitation_sum\n",
    "            daily_data[\"precipitation_hours\"] = daily_precipitation_hours\n",
    "            daily_data[\"wind_speed_10m_max\"] = daily_wind_speed_10m_max\n",
    "            daily_data[\"wind_gusts_10m_max\"] = daily_wind_gusts_10m_max\n",
    "            daily_data[\"et0_fao_evapotranspiration\"] = daily_et0_fao_evapotranspiration\n",
    "\n",
    "            return pd.DataFrame(data=daily_data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Erro ao solicitar dados da API para ({latitude}, {longitude}): {e}\")\n",
    "            if 'Minutely API request limit exceeded' in str(e):\n",
    "                print(\n",
    "                    \"Limite de requisições por minuto excedido. Tentando novamente em um minuto...\")\n",
    "                # Espera por 60 segundos antes de tentar novamente\n",
    "                time.sleep(60)\n",
    "                count_retry += 1\n",
    "            elif 'Hourly API request limit exceeded' in str(e):\n",
    "                print(\n",
    "                    \"Limite de requisições por hora excedido. Tentando novamente em uma hora...\")\n",
    "                # Espera por 3600 segundos (1 hora) antes de tentar novamente\n",
    "                time.sleep(3600)\n",
    "                count_retry += 1\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def agrupa_e_concatena_dados(df_iteracao: pd.DataFrame, df_resultados: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Agrupa os dados de iteração por ano e mês, calcula a média de cada coluna e concatena com o DataFrame de resultados.\n",
    "\n",
    "    Args:\n",
    "        df_iteracao (pd.DataFrame): DataFrame contendo os dados meteorológicos de uma iteração.\n",
    "        df_resultados (pd.DataFrame): DataFrame contendo os dados meteorológicos acumulados.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame resultante da concatenação dos dados agrupados de iteração com os dados acumulados.\n",
    "    \"\"\"\n",
    "    # Extrair Mês e Ano do DatetimeIndex\n",
    "    df_iteracao['ano'] = df_iteracao['date'].dt.year\n",
    "    df_iteracao['mes'] = df_iteracao['date'].dt.month\n",
    "\n",
    "    # Agrupar os dados por 'ano' e 'mes', e calcula a média de cada coluna\n",
    "    df_iteracao = df_iteracao.groupby(['ano', 'mes']).mean().reset_index()\n",
    "\n",
    "    return pd.concat([df_resultados, df_iteracao], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chamada da API e geração do dataset meteorológico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se há requisições a fazer\n",
    "total_de_requisicoes = len(df_treinamento_agrupado)\n",
    "print(\"Número de requisições a fazer:\", total_de_requisicoes)\n",
    "count = 1\n",
    "\n",
    "if len(df_treinamento_agrupado) > 0:\n",
    "    # iterar sobre cada grupo de coordenadas\n",
    "    for (latitude, longitude), group in df_treinamento_agrupado:\n",
    "        print(\"\\nRequisição\", count, \"de\", total_de_requisicoes)\n",
    "        local = group['local_de_instalacao'].iloc[0]\n",
    "\n",
    "        # Obter os dados meteorológicos da API\n",
    "        resposta = obtem_dados_api(latitude, longitude)\n",
    "        if isinstance(resposta, pd.DataFrame):\n",
    "            df_iteracao = resposta\n",
    "\n",
    "            # Concatenar os dados da iteração com os dados já existentes\n",
    "            df_resultados = agrupa_e_concatena_dados(\n",
    "                df_iteracao, df_resultados)\n",
    "\n",
    "            # Salva o dataset de dados meteorológicos\n",
    "            df_resultados.to_csv(\n",
    "                pathInput + 'dataset_dados_meteorologicos.csv', index=False)\n",
    "\n",
    "        else:\n",
    "            # Encerrar o loop caso a 'obtem_dados_api' retorne None\n",
    "            print(\"Número de retries excedido para\", local,\n",
    "                  \"(\", latitude, \",\", longitude, \").  Encerrando loop...\")\n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "else:\n",
    "    print(\"Nenhuma requisição a fazer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join com o dataset de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove colunas desnescessárias\n",
    "df_resultados.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Join com o dataset de treinamento\n",
    "df_treinamento = df_treinamento.merge(\n",
    "    df_resultados, on=['latitude', 'longitude', 'ano', 'mes'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporta dataset de treinamento com dados meteorológicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o dataset de treinamento com os dados meteorológicos\n",
    "df_treinamento.to_csv(pathUtil + 'dataset_treinamento_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
